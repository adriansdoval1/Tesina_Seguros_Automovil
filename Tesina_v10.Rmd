---
title: "Tesina Adri√°n Sandoval Cordero"
author: "Adri√°n Sandoval"
date: "2025-06-02"
output: pdf_document
lang: Es-es
fig_width: 4 
fig_height: 3 
---
\tableofcontents 
\newpage
\listoffigures
\newpage
\listoftables
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, fig.height=3, fig.width=4)
library(data.table)
library(ggplot2)
library(MASS)
library(rpart)
library(psych)
library(rpart.plot)
library(ModelMetrics)
library(ipred)
library(randomForest)
library(xgboost)
library(plotly)
library(fastDummies)
library(nortest)
library(lmtest)
library(car)
library(rstatix)
library(qqconf)
library(jtools)
library(stargazer)
library(rcompanion)
library(ggpubr)
library(cowplot)
library(caret)
library(corrplot)
library(bookdown)
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(patchwork)

benchmark_original_dt <- as.data.table(read.csv("C:/Users/klaym/OneDrive/Documentos/Especialidad Estad√≠stica Aplicada 2021/Tesina/base_tesina.csv"))

#qua_q_99 <- quantile(benchmark_original_dt$QUA_Desc_Num, probs = seq(0, 1, by= 0.0001))[9999]
#zurich_q_99 <- quantile(benchmark_original_dt$Zurich_Desc_Num, probs = seq(0, 1, by= 0.0001))[9999]


#benchmark_original_dt[,`:=`(QUA_Desc_Num = fifelse(QUA_Desc_Num > qua_q_99, qua_q_99, QUA_Desc_Num),
#                            Zurich_Desc_Num = fifelse(Zurich_Desc_Num > zurich_q_99, zurich_q_99, Zurich_Desc_Num))]
set.seed(123)
benchmark_model <- benchmark_original_dt


# Base final
benchmark_model[,`:=`(Log_QUA_Desc_Num = log(QUA_Desc_Num),
                      QUA_Desc_Num_sqrt = sqrt(QUA_Desc_Num),
                      Log_Siniestro_SA = log(SA_siniestro),
                      Log_Siniestro_SA_2 = log(SA_siniestro) ^ 2,
                      Log_Siniestro_SA_3 = log(SA_siniestro) ^ 3,
                      Log_Siniestro_SA_4 = log(SA_siniestro) ^ 4,
                      Log_Siniestro_SA_5 = log(SA_siniestro) ^ 5,
                      Log_Siniestro_SA_6 = log(SA_siniestro) ^ 6,
                      Log_Siniestro_SA_7 = log(SA_siniestro) ^ 7,
                      Log_Siniestro_SA_8 = log(SA_siniestro) ^ 8,
                      Siniestro_SA_2 = SA_siniestro ^ 2,
                      Siniestro_SA_3 = SA_siniestro ^ 3,
                      Siniestro_SA_4 = SA_siniestro ^ 4,
                      Siniestro_SA_5 = SA_siniestro ^ 5,
                      Siniestro_SA_6 = SA_siniestro ^ 6,
                      Siniestro_SA_7 = SA_siniestro ^ 7,
                      Siniestro_SA_8 = SA_siniestro ^ 8,
                      SA_siniestro_sqrt = sqrt(SA_siniestro),
                      Edad_Num = as.numeric(Edad),
                      Edad_Num_2 = as.numeric(Edad) ^ 2,
                      Atizapan_Zaragoza = fifelse(Municipio_D == "ATIZAPAN DE ZARAGOZA", 1, 0),
                      Atiz_Izt_GAM = fifelse(Municipio_D %in% c("ZAPOPAN", "ATIZAP√ÅN DE ZARAGOZA", "GUADALAJARA", 
                                                                "NAUCALPAN DE JUAREZ", "TOLUCA", "MORELIA"), 1, 0) ,
                      Pasajeros_5 = {
                        fifelse(as.numeric(Pasajeros) == 5, 1, 0)  
                      },
                      Edad_Cat = {
                        fifelse(as.numeric(Edad) <= 28, "Joven",
                                fifelse(as.numeric(Edad) < 66,"Mediana","Viejo"))
                      },
                      Carroceria_R = {fifelse(Carroceria %in% c("CONV", "CHASIS CABINA", "COUPE", 
                                                                "ESTACAS", "PANEL", "SW", "WAGON", "MINIVAN", "VAN",                                                                        "PICKUP"),"OTROS", Carroceria)
                        },
                      Marca_TP_R = {fifelse(Marca_TP %in% c("AUDI", "GMC", "COUPE", "MERCEDES BENZ",
                                                            "GMC", "INFINITI", "VOLVO", "DODGE", "CHEVROLET", "PORSCHE", "JEEP",
                                                            "BUICK", "CADILLAC", "DODGE", "TOYOTA", "BMW"),"GRUPO 1", "GRUPO_2")
                      })]

`%!in%` = function(x, y) !(x%in%y)

benchmark_model <- benchmark_model[Estado %!in% c("Baja California Sur", "Campeche", "Guerrero", 
                                                  "Durango", "Tlaxcala", "Zacatecas", "Tamaulipas",
                                                  "Oaxaca", "Hidalgo","Baja California", "Colima")]

#nrow(benchmark_model)
```

# 1. Introducci√≥n

El objetivo de este trabajo es comparar el desempe√±o predictivo de modelos tradicionales, como la Regresi√≥n Lineal y la regresi√≥n Lineal Generalizada, frente a una metodolog√≠a de Machine Learning, en particular el modelo de Gradient Boosting Machine (GBM). Se seleccion√≥ un problema del sector de seguros de da√±os ya que muchas de las variables que se manejan en este campo (como la suma asegurada, el tipo de veh√≠culo, la antiguedad del veh√≠culo etc.) son variables principalmente categ√≥ricas o que no tienen un comportamiento tradicional que hacen necesario el uso de modelos m√°s all√° del Modelo Lineal cl√°sico, o los pertenecientes a la familia exponencial como los Modelos Lineales Generalizados. Esto motiva la exploraci√≥n de enfoques m√°s flexibles como GBM, que pueden capturar relaciones no lineales y complejas entre las variables.

El problema seleccionado consiste en predecir el precio del seguro de autom√≥vil con cobertura amplia para una compa√±√≠a aseguradora, utilizando como base las caracter√≠sticas del veh√≠culo y la informaci√≥n del propietario. Este tipo de estimaci√≥n es de gran relevancia para las aseguradoras, ya que al comprender c√≥mo otras compa√±√≠as podr√≠an establecer sus precios permite fijar tarifas m√°s justas y competitivas, lo que puede traducirse en una mejor posici√≥n en el mercado.

Adem√°s, este trabajo usa el enfoque com√∫nmente utilizado en Ciencia de Datos para el desarrollo de modelos estad√≠sticos. Donde el proceso inicia con la selecci√≥n del problema a resolver, seguido del preprocesamiento y ajuste de los datos. Posteriormente, se elige la el modelo adecuado, se valida el modelo y, finalmente, se selecciona aquel que ofrezca el mejor desempe√±o predictivo.

Adicionalmente, se hace una breve introducci√≥n te√≥rica a los tres modelos usados en el trabajo:

+ Regresi√≥n Lineal
+ Regresi√≥n Gamma
+ XGradient Boosting (variaci√≥n de GBM)

Los primeros modelos son tradicionales en el √°rea de los seguros, y el √∫ltimo es una t√©cnica de Machine Learning que se populariz√≥ a mediados de la d√©cada del 2010.

Adicionalmente, se explica la necesidad de poder hacer una predicci√≥n sobre los precios de seguros de autom√≥vil con cobertura amplia obtenidos de una compa√±√≠a de seguros.

Para la validaci√≥n y comparaci√≥n de modelos se decidi√≥ dividir los datos en dos partes: una donde se entrenar√°n los modelos, y la otra se validar√°n los resultados. Adem√°s, se seleccionan algunas m√©tricas de validaci√≥n para poder comparar de manera justa los modelos, y poder determinar de manera estad√≠stica cual es la que ofrece mejores predicciones. Las m√©tricas de validaci√≥n vienen acompa√±adas de una gr√°fica que muestra la predicci√≥n por modelo y por variables para poder visualizar cual obtuvo el mejor ajuste comparando contra el precio real del seguro de autom√≥vil. Adicionalmente, se hace un gr√°fico de cuantiles que permite hacer una comparaci√≥n directa entre cada modelo. Cada estimaci√≥n de los modelos viene acompa√±ada de un an√°lisis de residuos, un an√°lisis de permanencia de variables, una transformaci√≥n logar√≠tmica de variable objetivo, y una comparativa entre coeficientes de informaci√≥n para asegurar que se obtuvo el resultado superior por cada metodolog√≠a.

Finalmente, se concluye que la t√©nica de Machine Learning ofrece estimaciones m√°s precisas basadas en las m√©tricas presentadas, an√°lisis de residuos y el an√°lisis visual. 

\newpage

# 2. Modelos Lineales

El Modelo Lineal y el Modelo Lineal Generalizado son t√©cnicas estad√≠sticas que han sido usadas en la industria de los seguros por muchos a√±os ya que ofrecen beneficios como:

+ Tener extensa bibliograf√≠a
+ Los resultados son interpretables
+ La estimaci√≥n de par√°metros est√° implementada en diversos programas
+ Es posible analizar inferencias

El cap√≠tulo se enfocar√° en dar una breve descripci√≥n de ambos modelos.

## 2.1 Modelo Lineal

El Modelo Lineal tiene como objetivo estimar el valor esperado de una variable $Y$, conocida como variable objetivo, utilizando un conjunto de variables $X$, denominadas variables explicativas o independientes. El modelo se expresa de la siguiente manera:

$$
Y=\beta_{0}+\beta_{1}X_{1}+...+\beta_{n}X_{n}+\epsilon ,
$$
donde $\epsilon\sim N(0,\sigma^2)$. 

Adicionalmente, este modelo se puede describir de manera matricial como sigue:

$$
\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
$$
Donde:

+ $\mathbf{Y} \in \mathbb{R}^{n \times 1}$ es el vector de la variable respuesta observado
+ $\mathbf{X} \in \mathbb{R}^{n \times p}$ es la matr√≠z de variables independientes
+ $\boldsymbol{\beta} \in \mathbb{R}^{p \times 1}$ es el vector de coeficientes
+ $\boldsymbol{\varepsilon} \in \mathbb{R}^{n \times 1}$ es el vector de residuos

La estimac√≥n de los par√°metros, $\beta=(\beta_1,...\beta_n)$, se hace minimizando la suma de residuos cuadrados (SCR) observados.

$$
 SRC =\sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - \mathbf{X}_i^T \boldsymbol{\beta})^2
$$

La cual se expresa de manera matricial como:

$$
(\mathbf{Y} - \mathbf{X} \boldsymbol{\beta})^T (\mathbf{Y} - \mathbf{X} \boldsymbol{\beta})
$$
Para encontrar los coeficientes se deben tomar las derivadas con respecto a $\boldsymbol{\beta}$ y se iguala a 0.

$$
\frac{\partial}{\partial \boldsymbol{\beta}} (\mathbf{y} - \mathbf{X} \boldsymbol{\beta})^T (\mathbf{y} - \mathbf{X} \boldsymbol{\beta}) = -2 \mathbf{X}^T (\mathbf{y} - \mathbf{X} \boldsymbol{\beta}) = 0
$$
Resolviendo la ecuaci√≥n anterior tenemos.

$$
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}
$$
Esta estimaci√≥n de coeficientes se conoce como M√≠nimos Cuadrados Ordinarios (MCO). Para que los coeficientes estimados sean consistentes (es decir, que converjan en probabilidad al valor verdadero a medida que aumenta el tama√±o de la muestra), insesgados, tengan varianza m√≠nima y sigan una distribuci√≥n normal, es necesario que se cumplan los siguientes supuestos:

+ $(\mathbf{X}^T \mathbf{X})$ es invertible (no existe multicolinealidad perfecta)
+ Independencia entre los errores
+ Homocedasticidad (varianza constante de los errores)
+ Los residuos $\boldsymbol{\varepsilon}$ tienen distribuci√≥n Normal con media 0, y son independientes de las variables en $X$

Una vez hecha la estimaci√≥n del modelo se necesita verificar que se cumplen todos los supuestos. Esto se puede hacer en $R$ llamando la funci√≥n $plot$ sobre el modelo estimado, y calcula 4 gr√°ficos que permiten verificar visualmente si los residuos tienen una distribuci√≥n Normal, si los residuos tienen varianza constante, si los residuos son independientes de las variables independientes, y la existencia de valores outliers que esten influenciando la estimaci√≥n. Esto √∫ltimo se hace con el c√°lculo de la distancia de Cook que es una medida que eval√∫a la influencia de una observaci√≥n en un modelo de regresi√≥n definida como:

$$
D_i = D_i = \frac{r_i^2}{p \cdot (1 - h_{ii})} \times h_{ii}
$$

Donde:

- $r_i$ es el residuo estandarizado, que son los residuos del modelo divididos por una estimaci√≥n de su desviaci√≥n est√°ndar, considerando el leverage de cada observaci√≥n.
- $h_{ii}$ es el leverage (elemento diagonal de la $(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T$).
- $p$ es el n√∫mero de par√°metros del modelo (incluyendo intercepto).

Finalmente, se hacen uso de la distribuci√≥n $t$ para poder crear dise√±ar una prueba de hip√≥tesis que permite identificar si una variable independiente es estad√≠sticamente significativa dentro del modelo es decir $H0:\beta_i=0$ para el coeficiente de alguna variable $i$.


## 2.2 Modelo Lineal Generalizado

El Modelo Lineal Generalizado se considera una extensi√≥n del Modelo Lineal y se representa de la siguiente forma:

$$
\mathbb{E}[Y|X_{1}=x_{1},...,X_{n}=x_{n}]=g(\beta_{0}+\beta_{1}x_{1}+...+\beta_{n}x_{n})
$$
La funci√≥n $g$ se llama funci√≥n liga, y tiene que ser inyectiva as√≠ como creciente (o decreciente). Adem√°s, la variable $Y$ tiene una distribuci√≥n que pertenece a la familia exponencial. Se dice que la variable aleatoria $Y$ pertenece a la familia exponencial si se puede expresar de la siguiente forma:

$$
f_Y(y; \theta, \phi) = c(y, \phi)\exp\left( \frac{y \cdot \theta - a(\theta)}{\phi}\right)
$$

Donde $\theta$ y $\phi$ son par√°metros.

Una de las caracter√≠sticas de las distribuciones que pertenecen a esta familia es que su esperanza y varianza se pueden caracterizar de la siguiente forma:

$$
  \mathbb{E}[Y] = a'(\theta)
$$
$$
  \mathrm{Var}(Y) = \phi \cdot a''(\theta)
$$
La siguiente tabla muestra algunas de las distribuciones que pertenecen a la familia exponencial:


| Distribuci√≥n| $\theta$| $a(\theta)$| $\phi$       |
|:----------:|:--------:|:----------:|:------------:|
| Normal|$\mu$|$\frac{1}{2} \mu^2$ | $\sigma^2$  |
| Bernoulli|$\ln\left(\frac{p}{1 - p}\right)$| $n\ln(1 + e^\theta)$|1|
| Poisson|$\ln(\lambda)$| $e^\theta$| 1 |
| Gamma|$-\lambda$|$-\ln(-\theta)$| $\frac{1}{v}$|
Table: Ejemplos de la Familia Exponencial

A diferencia de la regresi√≥n lineal, en este caso no existe una f√≥rmula cerrada para estimar los par√°metros mediante el m√©todo de M√≠nimos Cuadrados Ordinarios (MCO). Por ello, se recurre a la maximizaci√≥n de la log-verosimilitud para obtener las estimaciones.

$$
\ell(\boldsymbol{\beta}, \phi) = \sum_{i=1}^n\frac{(y_i \theta_i - a(\theta_i))}{\phi}+ c(y_i, \phi)
$$


La funci√≥n anterior se puede maximizar usando algoritmos iterativos como el m√©todo de Newton-Raphson, Fisher Scoring, o la metodolog√≠a de M√≠nimos Cuadrados Ponderados Iterados. La funci√≥n $glm$ de la paqueter√≠a $stats$ usa el m√©todo de M√≠nimos Cuadrasod Ponderados Iterados para encontrar los coeficientes.

Similar al Modelo Lineal hacen uso de la distribuci√≥n Normal para poder crear dise√±ar una prueba de hip√≥tesis que permite identificar si una variable independiente es estad√≠sticamente significativa dentro del modelo es decir $H0:\beta_i=0$ para el coeficiente de alguna variable $i$. La funci√≥n $glm$ tambi√©n calcula esta estad√≠stica por variable. 

\newpage

# 3. Modelo de XGradient Boosting

Para poder entender el modelo de XGradient Boosting (por sus siglas en ingl√©s Extreme Gradient Boosting) es necesario dar una breve introducci√≥n a los √Årboles de Regresi√≥n ya que constituyen la base esta metodolog√≠a.

## 3.1 √Årbol de Regresi√≥n

Un √Årbol de Regresi√≥n es un modelo estad√≠stico utilizado para predecir valores num√©ricos continuos a partir de un conjunto de datos. Cada observaci√≥n en el conjunto contiene una variable objetivo conocida y un conjunto de variables explicativas. El modelo construye una estructura en forma de √°rbol que divide los datos de manera secuencial en subconjuntos cada vez m√°s homog√©neos. 

La siguiente imagen es una representaci√≥n de la estructura de un √Årbol de Regresi√≥n. √âste modelo se estim√≥ usando los datos $mtcars$ de la paqueter√≠a $R$ hecha con la librer√≠a $rpart$. Estos datos contienen informaci√≥n sobre el rendimiento de 32 autos as√≠ como 10 caracter√≠sticas de estos. La variable objetivo es el rendimiento del veh√≠culo (Millas por Gal√≥n de Gasolina), y las variables explciativas son los Caballos de Fuerza y el Peso de Cada veh√≠culo.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Ejemplo de √Årbol de Regresi√≥n", fig.height = 3, fig.width = 5}

# Cargar datos y renombrar variables
datos <- mtcars
names(datos)[names(datos) == "wt"] <- "Peso"
names(datos)[names(datos) == "hp"] <- "Caballos de Fuerza"

# Crear el modelo de √°rbol de regresi√≥n
modelo <- rpart(mpg ~ Peso + `Caballos de Fuerza`, data = datos, method = "anova")

# Graficar el √°rbol con nombres legibles
rpart.plot(modelo, main = "√Årbol de regresi√≥n: Millas por Gal√≥n de Gasolina", type = 3, extra = 101)
```

Este √Årbol de Regresi√≥n contiene 2 nodos internos y 3 nodos terminales. Cada nodo terminal indica la predicci√≥n de Millas por Gal√≥n de Gasolina, la cantidad de observaciones que contiene el nodo, as√≠ como el porcentaje que estas representan del total. Por ejemplo, el primer nodo terminal (de izquierda a derecha) indica que los veh√≠culos que tienen un peso mayor o igual a 2.4 toneladas y una potencia (caballos de fuerza) superior a 178 rinden 14 Millas por Gal√≥n de Gasolina. Adicionalmente, este nodo agrupa 10 de 32 observaciones, lo que representa aproximadamente el 31% del conjunto de datos.

La siguiente gr√°fica ilustra como se dividi√≥ el espacio de las variables explicativas del √Årbol de Regresi√≥n anterior para poder calcular las predicciones de las Millas por Gal√≥n.

\newpage

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Partici√≥n del Espacio de Variables Predictoras", fig.height = 3, fig.width = 4}

# Cargar datos y renombrar variables
datos <- mtcars
names(datos)[names(datos) == "wt"] <- "Peso"
names(datos)[names(datos) == "hp"] <- "Caballos de Fuerza"

# Crear el modelo de √°rbol de regresi√≥n
modelo <- rpart(mpg ~ Peso + `Caballos de Fuerza`, data = datos, method = "anova")

# Crear una cuadr√≠cula para predecir
wt_seq <- seq(min(datos$Peso), max(datos$Peso), length.out = 200)
hp_seq <- seq(min(datos$`Caballos de Fuerza`), max(datos$`Caballos de Fuerza`), length.out = 200)
grid <- expand.grid(Peso = wt_seq, `Caballos de Fuerza` = hp_seq)

# Predecir mpg en cada punto de la cuadr√≠cula
grid$pred <- predict(modelo, newdata = grid)

# Graficar
ggplot() +
  geom_contour(data = grid, aes(x = Peso, y = `Caballos de Fuerza`, z = pred), color = "black", linewidth = 0.1) +
  geom_point(data = datos , aes(x = Peso, y = `Caballos de Fuerza`), color = "blue", size = 0.3) +
  labs(
    title = "Regiones de Decisi√≥n de un √Årbol de Regresi√≥n",
    x = "Peso del Auto (en miles de libras)",
    y = "Caballos de Fuerza"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 10))  # This goes here
```

En la gr√°fica se aprecia que para construir un √Årbol de Regresi√≥n se definieron 3 regiones que no est√°n superpuestas. Estas regiones corresponden a los 3 nodos terminales del gr√°fico del √Årbol de Regresi√≥n. Y, para obtener la predicci√≥n de las Millas por gal√≥n de Gasolina que aparece en cada nodo terminal se calcula el promedio de todas las observaciones de cada regi√≥n.

De manera general cuando se tiene un conjunto de datos $\{X_1,...,X_p\}$ con una variable explicativa $Y$ lo que se necesita para poder estimar un √Årbol de REgresi√≥n es lo siguiente:

1. Dividir el espacio de variables explicativas (es decir todo el conjunto de valores posibles para $X_1$,...,$X_p$) en $J$ distintas regiones $R_1$,...,$R_j$ que no est√©n superpuestas y que minimicen alguna funci√≥n objetivo.

2. Para obtener predicciones de cada observaci√≥n que pertenezca a la regi√≥n $R_i$ se calcula el promedio de las variables respuestas de las observaciones que se encuentren en esa regi√≥n.

Del ejemplo anterior, obtuvimos 3 regiones ($R_1$, $R_2$, y $R_3$) y el valor promedio de la variable respuesta en cada regi√≥n es 14, 20 y 29 Millas por Gal√≥n de Gasolina respectivamente. Entonces, para poder construir las regiones $R_1$,...,$R_j$ no superpuestas que minimicen una funci√≥n objetivo, es necesario definir tanto una forma factible de dividir el espacio de las variables explicativas como la funci√≥n objetivo. La funci√≥n objetivo utilizada en la literatura y para estimar un √Årbol de Regresi√≥n es el Error Cuadr√°tico (EC) que se define de la siguiente manera: 


$$
EC=\sum_{j=1}^{J} \sum_{i \in R_j}  (y_i - \hat{y}_{R_j})^2
$$


Donde $\hat{y}_{R_j}$ es el promedio de la variable respuesta para la observaci√≥n en la regi√≥n $j$. 

Esta funci√≥n objetivo se encuentra implementada en la funci√≥n $rpart$ de la librer√≠a $rpart$ en $R$. Adem√°s, la funci√≥n de p√©rdida utilizada en el modelo posee propiedades matem√°ticas importantes, como la convexidad y la doble derivabilidad (es decir, es una funci√≥n diferenciable de segundo orden). Estas caracter√≠sticas son fundamentales porque garantizan la existencia de un √∫nico m√≠nimo global.

Entonces, tenemos que definir una forma de dividir el espacio de variables explicativas en diferentes regiones no superpuestas. Dado que considerar todas las posibles particiones del espacio de variables explicativas resulta computacionalmente inviable, se recurre a un proceso llamado particionamiento recursivo binario descendente. Es decir, se comienza con un √∫nico nodo que contiene todas las observaciones y, en cada paso, se divide el espacio de las variables explicativas en dos ramas utilizando una de las variables explicativas. En cada iteraci√≥n, se selecciona la divisi√≥n que minimiza la funci√≥n objetivo, optimizando el ajuste del modelo.

Entonces, primero se selecciona la variable predictora $X_i$ y se selecciona un punto de corte $s$ tal que las regiones $R_1=\{X_i|X_i<s\}$ y $R_2=\{X_i|X_i>=s\}$ minimicen el EC. Despu√©s se selecciona otra variable $X_j$ y se hace lo mismo. De esta manera se consideran todas las posibles variables explicativas, diferentes puntos de corte, y aquella estimaci√≥n que minimice el EC. Aunque puede parecer un buen m√©todo existe el riesgo de que el √Årbol de Regresi√≥n resultante sea demasiado grande y tenga muchos nodos terminales (sea muy complejo) por lo que termine sobreajustado. Es decir, el √Årbol de Regresi√≥n set√° muy adaptado a las particularidades del conjunto de entrenamiento y, por lo tanto, generar predicciones poco confiables en nuevos datos. Para evitar este sobreajuste y, al mismo tiempo, no generar un √°rbol excesivamente simple (con muy pocos nodos), se incorpora un t√©rmino de penalizaci√≥n de complejidad a la funci√≥n objetivo a minimizar.

$$
\sum_{j=1}^{J} \sum_{i \in R_j}  (y_i - \hat{y}_{R_j})^2 + \alpha|T|
$$
Donde:

+ $|T|$ es el n√∫mero de nodos terminales.
+ $\alpha$ es el par√°metro de ajuste.

Mientras $\alpha$ se haga grande, vamos a tener un √Årbol de Regresi√≥n mucho menos complejo, pero si $\alpha=0$ regresamos al caso anterior es decir al √Årbol de Regresi√≥n sin restricciones. Por lo que la estimaci√≥n del √Årbol de Regresi√≥n se reduce a encontrar las regiones minimicen la funci√≥n objetivo anterior m√°s un t√©rmino de penalizaci√≥n de complejidad.

Finalmente, aunque se agrega un par√°metro adicional $\alpha$ que es fijo, la funci√≥n $rpart$ de la paqueter√≠a de $rpart$ en $R$ lo hace con validaci√≥n cruzada (Cross Validation) que es una t√©cnica estad√≠stica utilizada para evaluar el desempe√±o de un modelo predictivo de manera m√°s robusta, y lo que hace es dividir el conjunto de datos en $K$ subconjuntos del mismo tama√±o. El procedimiento se repite $K$ veces, de modo que en cada iteraci√≥n se utiliza uno de los subconjuntos como conjunto de validaci√≥n, y los $K-1$ restantes como conjunto de entrenamiento.


## 3.2 XGRadient Boosting

El Modelo XGradient Boosting (por sus siglas en ingl√©s Extreme Gradient Boosting) es una extensi√≥n optimizada de las metodolog√≠as de Gradient Boosting Machines y AdaBoost. Se encuentra implementada a trav√©s de la paqueter√≠a $xgboost$ con la funci√≥n $xgboost$ en $R$. De manera general la metodolog√≠a de XGradient Boosting consiste en entrenar secuencialmente peque√±os √Årboles de Regresi√≥n usando los residuos como variable objetivo para los siguientes √°rboles hasta obtener un nivel adecuado de precisi√≥n.

El algoritmo para estimar el modelo con un grupo de datos de tama√±o $m$, con $n$ variables explicativas y una variable obejtivo $y$ es el siguiente:

1. Establece $\hat{f}(x_1,...x_n)=0$ y $z=y$

2. Para $k=1,...,b$ se repite: 

> a) Estimar el √°rbol de decisi√≥n $\hat{f}^{k}$ de profundidad $p$ (con $p+1$ nodos terminales) a la base de datos

> b) Actualizar $\hat{f}$ de la siguiente manera

$$
\hat{f}(x_1,...x_n) \leftarrow\hat{f}(x_1,...x_n)+\eta*\hat{f}^{(k)}(x_1,...x_n)
$$

>> donde $\eta$ es la tasa de aprendizaje que determina la influencia del √°rbol en las estimaciones subsecuentes y es un par√°metro predefinido.

> c) Actualizar los residuos $z$ de la siguiente manera

$$
z \leftarrow z-\eta*\hat{f}^{(k)}(x_1,...x_n)
$$

3. Se repiten $b$ veces los pasos en 2 o hasta que se cumpla alg√∫n requisito de precisi√≥n establecido, por ejemplo una reducci√≥n de la funci√≥n objetivo no significativa con respecto al √°rbol anterior

4. Para poder obtener una estimaci√≥n se hace la suma de todas las predicciones de los √°rboles calculado de la siguiente manera:

$$
\hat{f}(x_1,...x_n)=\sum_{k=1}^{b}{\eta*{f}^{(k)}(x_1,...x_n)}.
$$

Usualmente se usan √Årboles de Regresi√≥n de poca profundidad y se estiman usando un criterio que minimice alguna funci√≥n objetivo como la definida en el cap√≠tulo anterior. De acuerdo a Gareth James et al. la mejor t√©cnica para encontrar el hiperpar√°metro $b$ es usando validaci√≥n cruzada, as√≠ mismo el mismo autor sugiere que el hiperpar√°metro $\eta$ var√≠a de acuerdo al problema, por lo que no existe una sugerencia.

Adem√°s, aunque no hay una forma definitiva para encontrar el par√°metro $p$, de acuerdo a Gareth James et al. un par√°metro de $p=1$ funciona bien.

El siguiente diagrama muestra de manera visual como el algoritmo genera diferentes √Årboles de Regresi√≥n usando recursivamente los residuos mientras se minimiza alguna funci√≥n objetivo. Al final la predicci√≥n para un dato es la suma ponderada del resultado de cada √°rbol de decisi√≥n. 

\newpage

```{r, echo = FALSE, message = FALSE, fig.align = 'center', fig.cap = "Diagrama de 3 Iteraciones del Algoritmo del Modelo de XGradient Boosting", out.width="60%", out.height="40%"}

graph <- grViz("
digraph xgboost_process {
  
  graph [layout = dot, rankdir = TB]
  node [shape = rectangle, style = filled, fillcolor = lightblue, fontname = Helvetica, fontsize = 12]

  datos        [label = 'üì¶ Datos de Entrada\n(Ej: Variables Independientes y Variables Dependiente)']
  arbol1       [label = 'üå≥ √Årbol 1\nPredicci√≥n inicial']
  residuos1  [label = 'üîÅ Calcular Residuos\n √Årbol 1']
  arbol2       [label = 'üå≥ √Årbol 2\nResiduos']
  residuos2  [label = 'üîÅ Calcular Residuos\n √Årbol 2']
  arbol3       [label = 'üå≥ √Årbol 3\nResiduos']
  residuos3  [label = 'üîÅ Calcular Residuos\n √Årbol 3']
  suma         [label = '‚ûï Suma Ponderada de Predicciones']
  pred_final   [label = '‚úÖ Predicci√≥n final\nModelo optimizado']

  datos -> arbol1
  datos -> arbol2
  datos -> arbol3
  arbol1 -> residuos1
  residuos1 -> suma
  residuos1 -> arbol2
  arbol2 -> residuos2
  residuos2 -> suma
  residuos2 -> arbol3
  arbol3 -> residuos3 
  residuos3 -> suma
  suma -> pred_final
  
      { rank = same; arbol1;arbol2 }
      { rank = same; arbol1;arbol3 }
}
")


# Convertir a SVG y luego a PDF para incrustar
svg <- export_svg(graph)
tmp_svg <- tempfile(fileext = ".svg")
writeLines(svg, tmp_svg)
tmp_pdf <- tempfile(fileext = ".pdf")
rsvg_pdf(tmp_svg, tmp_pdf)

# Incluir la imagen PDF generada
knitr::include_graphics(tmp_pdf)

```


Al igual que en el caso del √Årbol de Regresi√≥n, una vez definido el algoritmo para obtener la estimaci√≥n, es necesario establecer una funci√≥n objetivo que gu√≠e el proceso de optimizaci√≥n. Una de las principales diferencias de XGradient Boosting respecto a otras metodolog√≠as es que los √Årboles de Regresi√≥n se entrenan de forma secuencial: primero se construye un √°rbol, y luego se agregan sucesivos √°rboles, uno a uno, durante $b$ iteraciones o hasta que se cumpla un criterio de parada. Cada nuevo √Årbol de Regresi√≥n se ajusta para corregir los errores residuales cometidos por el conjunto de √°rboles anteriores, lo que permite mejorar progresivamente la precisi√≥n del modelo.

De acuerdo a Tianqi Chen y Carlos Guestrin (2016) para este modelo se usa la siguiente funci√≥n objetivo para encontrar el √Årbol de Regresi√≥n en el paso $t$ ($t<=b$).

$$
 \sum_{i=1}^{n} l(y_i, \hat{y}_i^{(t)}) + \sum_{k=1}^{t} \omega(f_k)
$$

Donde:

- $l(y_i, \hat{y}_i^{(t)})$: Funci√≥n de p√©rdida que mide la diferencia entre la predicci√≥n del modelo $\hat{y}_i^{(t)}$ en la iteraci√≥n $t$ y el valor real $y_i$.
- $\omega(f_k)$: Es una funci√≥n que tiene el objetivo de mide la complejidad de un √Årbol de Regresi√≥n $f_k$ y es un t√©rmino de regularizaci√≥n que penaliza la complejidad del √Årbol de Regresi√≥n $f_k$
- $n$: N√∫mero total de observaciones en el conjunto de datos.
- $t$: N√∫mero total de √°rboles construidos hasta la iteraci√≥n actual.

El problema con minimizar la funci√≥n anterior es que el t√©rmino $\omega(f_t)$ no puede minizarse de manera tradicional al estar en funci√≥n de un √Årbol de Regresi√≥n, es decir no podemos encontrar un √Årbol de Regresi√≥n que minimice la funci√≥n $\omega(.)$ usando t√©cnicas anal√≠ticas tradicionales. Entonces, la estimaci√≥n $\hat{y}_i^{(t)}$ se puede desarrollar como:

$$
\hat{y}_i^{(0)} = 0
$$

$$
\hat{y}_i^{(1)} = f_1(x_i) = \hat{y}_i^{(0)} + f_1(x_i)
$$

$$
\hat{y}_i^{(2)} = f_1(x_i) + f_2(x_i) = \hat{y}_i^{(1)} + f_2(x_i)
$$

$$
\vdots
$$

$$
\hat{y}_i^{(t)} = \sum_{k=1}^{t} f_k(x_i) = \hat{y}_i^{(t-1)} + f_t(x_i)
$$

Por lo tanto, que se encontr√≥ una forma de representar la funci√≥n objetivo del t-√©simo √Årbol de Regresi√≥n como una suma de estimaciones anteriores m√°s el t-√©simo √Årbol de Regresi√≥n. Sustituyendo en la ecuaci√≥n original, se puede expresar la funci√≥n objetivo en t como:

$$
\text{obj}^{(t)} = \sum_{i=1}^{n} l(y_i, \hat{y}_i^{(t)}) + \sum_{k=1}^{t} \omega(f_k) = \sum_{i=1}^{n} l\left(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)\right) + \omega(f_t) + \sum_{k=1}^{t-1} \omega(f_k) 
$$
Se puede aproximar la funci√≥n objetivo $l(x,y)$ usando la expansi√≥n de Taylor alrededor de $\hat{y}_i^{(t-1)}$ hasta el segundo t√©rmino.


$$
l(y_i, \hat{y}_i^{(t-1)}+f_t(x_i)) \approx l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)^2
$$

Donde:

- $g_i = \left. \frac{\partial l(y_i, \hat{y})}{\partial \hat{y}} \right|_{\hat{y} = \hat{y}_i^{(t-1)}}$ es el gradiente.
- $h_i = \left. \frac{\partial^2 l(y_i, \hat{y})}{\partial \hat{y}^2} \right|_{\hat{y} = \hat{y}_i^{(t-1)}}$ es el Hessiano o segunda derivada.

Sustituyendo la expansi√≥n de Taylor en la funci√≥n objetivo:

$$
\text{obj}^{(t)} \approx \sum_{i=1}^n \left[ l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)^2 \right] + \omega(f_t) + \sum_{k=1}^{t-1} \omega(f_k) 
$$
Excluyendo los t√©rminos constantes que no influyen en la minimizaci√≥n, entonces tenemos:

$$
\text{obj}^{(t)} \approx \sum_{i=1}^n \left[ g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)^2 \right] + \omega(f_t)
$$

Tianqi Chen y Carlos Guestrin (2016) usan la siguiente definici√≥n para $\omega(f_t)$:

$$
\omega(f_t) =  \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^2 
$$
Donde $w_{q(x)} \in \mathbb{R}^T$ es un vector con los valores estimados en cada nodo terminal del t-√©simo √Årbol de Regresi√≥n, y $q:\mathbb{R}^n \rightarrow \{1,2,...,T\}$ es una funci√≥n que asigna cada dato a un nodo terminal donde $T$ es el n√∫mero de nodos terminales. Por lo tanto, la funci√≥n $w_{q(x)}$ es un vector con los valores estimados en cada nodo terminal del t-√©simo √Årbol de Regresi√≥n, y $q$ es una funci√≥n que asigna cada dato a un nodo terminal de ese √°rbol.

De esta forma podemos tener una funci√≥n objetivo que se puede minimizar:

$$
\text{obj}^{(t)} \approx \sum_{i=1}^n \left[ g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)^2 \right] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^2  
$$

Agrupando y usando las definiciones anteriores podemos llegar a la siguiente expresi√≥n:

$$
\text{obj}^{(t)} \approx \sum_{i=1}^{n} \left[ g_i w_{q(x_i)} + \frac{1}{2} h_i w_{q(x_i)}^2 \right] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_j^2 
$$
Dado que cada nodo terminal asigna la misma predicci√≥n a todos los datos que contiene, el t√©rmino anterior puede reescribirse de la siguiente forma:

$$
\text{obj}^{(t)} \approx \sum_{j=1}^{T} \left[ \left( \sum_{i \in I_j} g_i \right) w_j + \frac{1}{2} \left( \sum_{i \in I_j} h_i + \lambda \right) w_j^2 \right] + \gamma T
$$

Done $I_j=\{i|q(x_i)=j\}$ representa el conjunto de √≠ndices de las observaciones asignadas al j-√©simo nodo terminal. As√≠ mismo podemos hacer la expresi√≥n manera m√°s peque√±a si definimos lo siguiente:

$$
G_j = \sum_{i \in I_j} g_i \quad \text{y} \quad H_j = \sum_{i \in I_j} h_i
$$
As√≠ terminamos con la siguiente expresi√≥n para la funci√≥n objetivo del t-√©simo √Årbol de Regresi√≥n a minimizar.

$$
\text{obj}^{(t)} = \sum_{j=1}^{T} \left[ G_j w_j + \frac{1}{2} (H_j + \lambda) w_j^2 \right] + \gamma T
$$
Sin embargo, tambi√©n se puede encontrar el $w_j$ que minimiza la funci√≥n anterior derivando con respecto a $w_j$ e igualandola a 0. As√≠ obtenemos que la funci√≥n objetivo alcanza el m√≠nimo cuando.

$$
w_j^{*}=-\frac{G_j}{H_j + \lambda}
$$
Y al substituirla en la funci√≥n objetivo tenemos que el m√≠nimo valor de la funci√≥n objetivo es:

$$
\text{obj}^{(*)}  = -\frac{1}{2}\sum_{j=1}^{T} \frac{G_j^2}{H_j + \lambda} + \gamma T
$$

La expresi√≥n anterior evaluada para una $j$ se llama "Score" que se utiliza para evaluar la calidad de una posible divisi√≥n en la estructura del √Årbol de Regresi√≥n dentro del modelo XGBoost. Durante el proceso de construcci√≥n del √°rbol en la iteraci√≥n t, esta m√©trica permite estimar la reducci√≥n esperada del error al considerar una variable explicativa $X_i$ como punto de partici√≥n. En otras palabras, el "Score" ayuda a determinar qu√© divisi√≥n produce la mayor ganancia en t√©rminos de ajuste del modelo, guiando as√≠ la selecci√≥n √≥ptima de variables y puntos de corte en cada nodo del √°rbol.

La paqueter√≠a de $xgboost$ tiene la funci√≥n $xgb.plot.importance$ la cual utiliza el score como base para calcular la ganancia ("Gain") asociada a cada variable explicativa. Esta m√©trica representa la contribuci√≥n promedio de cada variable a la reducci√≥n del error del modelo a lo largo de todos los √°rboles. En esencia, el "Gain" mide cu√°nto mejora el modelo, en t√©rminos de su funci√≥n objetivo, al utilizar una variable determinada como criterio de divisi√≥n en los nodos del √°rbol.

El c√°lculo del "Gain" de cada variable $i$ es el siguiente:

$$
Gain_i=Score\ Antes\ de\ Dividir\ por\ Variable\ i -(Score\ Nodo\ Izquierdo+Score\ Nodo\ Derecho)
$$

Aunque una de las principales ventajas del modelo XGBoost es su alta capacidad predictiva (superando habitualmente el desempe√±o de un solo √Årbol de Regresi√≥n de acuerdo a Gareth James et al.), esto se debe a que XGBoost construye un conjunto de √°rboles secuenciales, donde cada uno corrige los errores del anterior, lo que genera una estructura compleja dif√≠cil de descomponer e interpretar de forma directa. A diferencia de un √Årbol de Regresi√≥n individual, cuya l√≥gica de decisi√≥n puede visualizarse f√°cilmente. La siguiente imagen muestra el "Gain" del modelo del cap√≠tulo anterior que usa los datos $mtcars$, pero usando la metodolog√≠a de XGradient Boosting con 10 iteraciones, par√°metro $\eta=0.5$, $\gamma = 0$ y los √Årboles de Regresi√≥n con profundidad de 1.


```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Ejemplo de Importancia de Variables", fig.height = 2, fig.width = 3}


# Usar mtcars: predeciremos 'mpg' (consumo) usando el resto como predictores
data(mtcars)

# Convertir a matriz y separar variables
X <- as.matrix(mtcars[,c(4, 6)])  # Predictores (sin mpg)
y <- mtcars$mpg               # Variable respuesta

# Crear estructura de datos para xgboost
dtrain <- xgb.DMatrix(data = X, label = y)


# Entrenar un modelo simple
modelo <- xgboost(
  data = dtrain,
  objective = "reg:squarederror",  # Para regresi√≥n
  nrounds = 3,                    # N√∫mero de iteraciones
  verbose = 0,                      # Silencia la salida
    eta = 0.5, 
  max_depth = 1,
  gamma = 0
)



# Obtener la importancia de las variables
importancia <- xgb.importance(model = modelo)

# Mostrar tabla (opcional)
#print(importancia)

# Graficar importancia
#xgb.plot.importance(importancia, top_n = 10)

#importance <- xgb.plot.importance(importancia, top_n = 10)

importancia$Nombre <- c("Peso", "Caballos de Fuerza")

#xgb.plot.importance(importance_matrix, 
#                    rel_to_first = FALSE, 
#                    xlab = "Importancia", 
#                    top_n = 4) 

ggplot(importancia, aes(x = reorder(Nombre , Gain), y = Gain)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  ggtitle("Importancia de Variables") +
  labs(x = "Variable", y = "Ganancia") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 8, face = "bold")
  )




```


En el ejemplo se observa que la variable m√°s importante fu√© el peso del autom√≥vil ("wt") ya que representa m√°s del 60% del Gain total del modelo. 

Haciendo una comapraci√≥n de las estimaciones con el modelo obtenido en el √Årbol de Regresi√≥n del cap√≠tulo anterior podemos ver lo siguiente:



```{r, echo=FALSE, message = FALSE, results = "hide"}

# Cargar datos
data(mtcars)

# Seleccionar predictores y variable objetivo
X <- as.matrix(mtcars[, c("wt", "hp")])  # Predictores
y <- mtcars$mpg                          # Respuesta

# Crear objeto DMatrix para XGBoost
dtrain <- xgb.DMatrix(data = X, label = y)

modelo_xgb <- xgboost(
  data = dtrain,
  objective = "reg:squarederror",
  nrounds = 10,
  verbose = 0,
  eta = 0.5, 
  max_depth = 1,
  gamma = 0
)

# Predicciones con XGBoost
pred_xgb <- predict(modelo_xgb, X)

# Convertir a data.frame para rpart
df <- mtcars[, c("mpg", "wt", "hp")]

# Ajustar modelo rpart
modelo_rpart <- rpart(mpg ~ wt + hp, data = df)

# Predicciones con rpart
pred_rpart <- predict(modelo_rpart, newdata = df)


# Crear tabla de comparaci√≥n
resultados <- data.frame(
  Real = y,
  XGBoost = round(pred_xgb, 2),
  RPart = round(pred_rpart, 2)
)

# Mostrar tabla
#kable(resultados, caption = "Comparaci√≥n de predicciones: XGBoost vs rpart")


```

|                    | Real| XGBoost| √Årbol de Regresi√≥n|
|:-------------------|----:|-------:|-----:|
|Mazda RX4           | 21.0|   21.88| 19.79|
|Mazda RX4 Wag       | 21.0|   21.88| 19.79|
|Datsun 710          | 22.8|   21.88| 29.03|
|Hornet 4 Drive      | 21.4|   21.88| 19.79|
|Hornet Sportabout   | 18.7|   17.62| 19.79|
|Valiant             | 18.1|   20.61| 19.79|
|Duster 360          | 14.3|   13.81| 14.28|
|Merc 240D           | 24.4|   23.73| 19.79|
|Merc 230            | 22.8|   21.88| 19.79|
|Merc 280            | 19.2|   17.62| 19.79|
|Merc 280C           | 17.8|   17.62| 19.79|
|Merc 450SE          | 16.4|   16.34| 14.28|
|Merc 450SL          | 17.3|   16.34| 14.28|
|Merc 450SLC         | 15.2|   16.34| 14.28|
|Cadillac Fleetwood  | 10.4|   12.89| 14.28|
|Lincoln Continental | 10.4|   12.89| 14.28|
|Chrysler Imperial   | 14.7|   12.89| 14.28|
|Fiat 128            | 32.4|   29.46| 29.03|
|Honda Civic         | 30.4|   31.32| 29.03|
|Toyota Corolla      | 33.9|   31.32| 29.03|
|Toyota Corona       | 21.5|   21.88| 19.79|
|Dodge Challenger    | 15.5|   16.34| 19.79|
|AMC Javelin         | 15.2|   17.62| 19.79|
|Camaro Z28          | 13.3|   13.81| 14.28|
|Pontiac Firebird    | 19.2|   16.34| 19.79|
|Fiat X1-9           | 27.3|   29.46| 29.03|
|Porsche 914-2       | 26.0|   27.62| 29.03|
|Lotus Europa        | 30.4|   29.48| 29.03|
|Ford Pantera L      | 15.8|   15.09| 14.28|
|Ferrari Dino        | 19.7|   17.62| 19.79|
|Maserati Bora       | 15.0|   13.81| 14.28|
|Volvo 142E          | 21.4|   21.88| 19.79|
Table: Comparaci√≥n de predicciones: XGBoost contra √Årbol de Regresi√≥n

Se observa que ambos modelos capturan en t√©rminos generales la tendencia de los valores reales; sin embargo, presentan diferencias en la precisi√≥n de sus predicciones. En particular, el modelo de XGBoost tiende a ajustarse mejor en ciertos casos. Por ejemplo, para el autom√≥vil Merc 240D, el √Årbol de Regresi√≥n subestima notablemente el valor real, mientras que XGBoost proporciona una predicci√≥n mucho m√°s cercana. Este comportamiento refleja la capacidad de XGBoost para modelar relaciones m√°s complejas entre las variables.


\newpage

# 4. Propuesta de Validaci√≥n de los Modelos

Aunque el objetivo principal de este trabajo es identificar el modelo con las mejores capacidades predictivas, tambi√©n resulta fundamental evaluar su capacidad de inferencia. Esto permite determinar en qu√© medida el modelo puede generalizar los resultados y, por ende, realizar predicciones confiables. Por esta raz√≥n, la propuesta incluye la validaci√≥n de los supuestos del Modelo Lineal, el an√°lisis de la permanencia de variables, as√≠ como la consideraci√≥n de una transformaci√≥n logar√≠tmica de las variables. Finalmente, se usan algunas m√©tricas con un an√°lisis visual para determinar si el modelo tiene buena capacidad predictiva. Los siguientes puntos presentan para la validaci√≥n de los supuestos de los modelos.

Para el Modelo Lineal y el Modelo Lineal Generalizado se har√° lo siguiente:

+ Se evaluar√° la permamencia de variables explicativas utilizando como criterio el $p-value$. Adicionalmente, se evaluar√° si la estimaci√≥n es adecuada de acuerdo a la m√©trica de $R^2-ajustada$ y en el caso del Modelo Lineal se har√° un an√°lisis visual de los supuestos usando la funci√≥n $plot$ de la paqueter√≠a base de $R$ la cual genera diferentes gr√°ficas diagn√≥sticas que permiten evaluar si los supuestos del modelo se cumplen adecuadamente. 

+ Adem√°s, la funci√≥n $plot$ permite visualizar la distancia de Cook, una medida √∫til para identificar observaciones influyentes o posibles outliers en el modelo.

+ Se realizar√° un an√°lisis de residuos para evaluar la relaci√≥n entre los valores estimados y los valores reales. Esto permite determinar qu√© tan bien las predicciones del modelo capturan el comportamiento real de los datos.

+ Se repetir√° el procedimiento del punto anterior, pero aplicando una transformaci√≥n logar√≠tmica a la variable objetivo y a algunas variables explicativas (como la Suma Asegurada). Ya que esta transformaci√≥n puede mejorar el desempe√±o del modelo al estabilizar la varianza y reducir la influencia de valores at√≠picos, lo que potencialmente mejora la capacidad predictiva. Una vez realizada la estimaci√≥n con la variable objetivo transformada, se comparar√°n los modelos utilizando el Coeficiente de Informaci√≥n Bayesiano (CIB), con el fin de evaluar cu√°l ofrece un mejor ajuste.

Los pasos anteriores se har√°n dentro del cap√≠tulo de la estimaci√≥n de cada modelo. Adem√°s, se utilizar√° la transformaci√≥n que haya demostrado el mejor desempe√±o en los an√°lisis anteriores al aplicar el modelo de XGBoost, con el fin de garantizar una comparaci√≥n m√°s justa y consistente entre metodolog√≠as. El modelo de XGBoost tambi√©n tendr√° un an√°lisis de importancia de variables as√≠ como se describi√≥ en el cap√≠tulo 3.2.

Asimismo, con el fin de validar la capacidad predictiva de los modelos, se dividir√°n los datos en dos partes: el 80% se utilizar√° para el ajuste del modelo, mientras que el 20% restante se destinar√° a su validaci√≥n. Esto permitir√° obtener m√©tricas que faciliten la comparaci√≥n de su desempe√±o predictivo. Las m√©tricas empleadas ser√°n las siguientes:

  + Error Porcentual Absoluto Medio (EPAM): esta m√©trica mide el porcentaje promedio de separaci√≥n del precio real del seguro de autom√≥vil contra el precio del seguro de autom√≥vil estimado. La m√©trica es √∫til ya que es una comparaci√≥n en t√©rminos porcentuales, la f√≥rmula es la siguiente

$$
EPAM=\frac{1}{n}\sum_{i=1}^{n}\left|\frac{\hat{Y}_i-{Y}_{i}}{{Y}_{i}}\right|.
$$


  + Error Absoluto Medio (EAM): esta m√©trica mide la diferencia absoluta con la estimaci√≥n del modelo. La m√©trica es √∫til ya que ofrece una comparaci√≥n en pesos en t√©rminos absolutos, con f√≥rmula

$$
EAM=\frac{1}{n}\sum_{i=1}^{n}\left|\hat{Y}_i-{Y}_{i}\right|.
$$

  + Ra√≠z del Error Cuadr√°tico Medio (ECM): esta m√©trica mide la diferencia cuadrada entre el precio real del seguro de autom√≥vil con la del estimado, cuya f√≥rmula es
  
$$
ECM=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(\hat{Y}_i-{Y}_{i})^2}.
$$  

Adem√°s de las m√©tricas se har√°n unas gr√°ficas con los datos de validaci√≥n que permiten comaprar los resultados del modelo por variable. Dependiendo del tipo de la variable (categ√≥rica o continua) se hace un histograma o un diagrama de barras. Por cada intervalo del histograma o categor√≠a del diagrama se calcula el promedio del valor real y el promedio del valor estimado. Esto nos permite identificar que modelo sigue mejor el precio real por variable, y poder evaluar a un nivel m√°s desagregado los resultados finales. Cada an√°lisis se hizo por las variables m√°s importantes que son el municipio del asegurado, intervalo de suma asegurada y la marca del autom√≥vil. Aunque se usaron m√°s variables para estimar los modelos se decidi√≥ enforcarse en esas variables ya que tienen m√°s categor√≠as, y esto ofrece una visualizaci√≥n m√°s clara sobre la precisi√≥n de cada modelo.

Finalmente, de acuerdo a Mark Goldburd, FCAS, MAAA et al. se puede hacer una comparaci√≥n visual y directa entre modelos usando los gr√°ficos de cuantiles que son una representaci√≥n visual y sencilla de la capacidad predictiva de una modelo. La forma en la que se hace es la siguiente:

1. Ordernar el conjunto de predicciones de menor a mayor.

2. Agrupar los datos en cuantiles (usualmente se agrupan en quintiles o deciles).

3. Dentro de cada intervalo calcular el promedio del valor real y el promedio del valor estimado

Para poder determinar el modelo que ofrezca un mejor valor predictivo se deben considerar 3 cosas

+ La cercan√≠a del valor del modelo al valor real

+ El valor del modelo debe aumentar de forma mon√≥tona al aumentar el cuantil, as√≠ como el valor real

+ Una diferencia grande (tambi√©n llamada ‚Äúlift‚Äù) entre el promedio del valor real en el cuantil m√°s bajo y el m√°s alto. Ya que esto indica que el modelo es capaz de distinguir entre los valores reales m√°s altos y bajos.

Para cada modelo se elaborar√° un gr√°fico de cuantiles con los datos de validaci√≥n y se calcular√° su ‚Äúlift‚Äù con el objetivo de identificar aquel con el mejor desempe√±o predictivo.

El mejor modelos en capacidades predictivas ser√° aquel que tengas las m√©tricas de error m√°s bajas, y cuyos an√°lisis visuales represente el mejor ajuste.

\newpage

# 5. Aplicaci√≥n

En este cap√≠tulo se presenta una aplicaci√≥n pr√°ctica de los modelos estad√≠sticos descritos en los cap√≠tulos anteriores, espec√≠ficamente en el contexto del sector asegurador. El objetivo es demostrar que el modelo de XGradient Boosting representa una alternativa eficaz para abordar problemas reales en el sector asegurador, ofreciendo adem√°s una mejora significativa en la capacidad predictiva en comparaci√≥n con metodolog√≠as m√°s tradicionales.

A trav√©s de esta aplicaci√≥n, se busca ilustrar el proceso completo de modelaci√≥n: desde la presentaci√≥n del problema, la selecci√≥n de variables, la preparaci√≥n de los datos, la selecci√≥n del modelo adecuado, su ajuste y validaci√≥n. 

## 5.1 Definici√≥n del Problema

El seguro de autom√≥vil es obligatorio para poder manejar dentro del territorio Mexicano de acuerdo al art√≠culo 63 Bis de la Ley de Caminos, Puentes y Autotransporte Federal. Adem√°s, la CONDUSEF indic√≥ en 2021 que el 36% de la poblaci√≥n adulta cuenta con seguro de autom√≥vil. Entonces, m√°s de la mitad de la poblaci√≥n que maneja en M√©xico no est√° protegida ante el riesgo de un accidente, robo, gastos m√©dicos o da√±os a terceros. Lo anterior se debe a que un factor importante que hace que las personas no compren un seguro de autom√≥vil es el costo que a veces llega a fluctuar mucho o suele ser alto. Sin embargo, para que las empresas aseguradoras puedan reducir los costos del seguro sin afectar sus utilidades deben considerar diversos factores, pero uno que se ha vuelto muy importante en los √∫ltimos a√±os son los precios de seguros de otras compa√±√≠as aseguradoras ya que sus metodolog√≠as o t√©cnicas de c√°lculo no suelen compartirse a detalle. Por lo que hace dif√≠cil que se puedan replicar. Aunque no se pueden conocer todas las metodolog√≠as exactas de las empresas aseguradoras si podemos tener informaci√≥n sobre el precio final en funci√≥n de diversas caracter√≠sticas del asegurado, y con esa informaci√≥n poder hacer un modelo estad√≠stico que permita predecir que los precios (sin conocer la metodolog√≠a) e incluirlos c√°lculo m√°s justo del precio del seguro. Por ejemplo, es posible usar la predicci√≥n del precio de otras compa√±√≠as de seguro para cuantificar en que medida se puede reducir/ aumentar el precio final de un seguro que garantize un precio justo, adecuado al mercado y que sea para el alcance de los usuarios.

El objetivo de la aplicaci√≥n es poder estimar el precio calculado por una empresa de seguros que comparti√≥ su informaci√≥n haciendo uso de los diferentes atributos del asegurado, y las caracter√≠sticas del autom√≥vil. Esto se hace con la intenci√≥n de poder identificar qu√© factores usa una compa√±√≠a de seguros, y poder predecir el precio final asumiendo que los precios se van a compartir entre empresas de seguros.

La predicci√≥n se har√° con las siguientes 3 metodolodg√≠as: 

+ Regresi√≥n Lineal
+ Regresi√≥n Gamma
+ XGradient Boosting

Por lo tanto, el objetivo es predecir el precio del seguro de autom√≥vil con cobertura amplia y se confirmar√° que para este problema la t√©cnica de Machine Learning tiene mayor poder predictivo que el resto de metodolog√≠as tradicionales. En la aplicaci√≥n se usa una base de datos que contiene diferentes precios de seguro de autom√≥vil bajo diferentes caracter√≠sticas del asegurado y del autom√≥vil. 

## 5.2 Descripici√≥n de los Datos Utilizados

```{r, echo=FALSE, results = "hide"}
benchmark_model <- benchmark_model[QUA_Desc_Num <= 30000]
nrow(benchmark_model)
```

Los datos utilizados son desagrupados y comprenden un total de $16,942$ cotizaciones de seguros de auto con cobertura amplia. Estas cotizaciones abarcan diversos tipos de veh√≠culos, incluyendo Sed√°n, SUV y camiones ligeros, ubicados en distintos estados del pa√≠s. Los datos representan una muestra del tipo de veh√≠culos com√∫nmente encontrados en la Rep√∫blica Mexicana y las cotizaciones fueron realizadas por una compa√±√≠a aseguradora en el a√±o 2021, por lo que no reflejan los precios actuales del mercado. Finalmente, solo se consideraron cotizaciones menores a $30,000 pesos.

A continuaci√≥n, se muestra un ejemplo del tipo de informaci√≥n utilizada:

|     Estado     |     Submarca_TP     | Modelo | ... | Desc_Num |
|:--------------------:|:--------------------------:|:-------:|:---:|:-----------:|
| Aguascalientes | JEEP-GRAND CHEROKEE |  2015  | ... |  $8,318  |
Table: Ejemplo de la Estructura de los Datos

En el ejemplo vemos que el seguro con cobertura amplia para una Jeep-Grand Cherokee modelo 2015 ubicada en Aguascalientes tiene un precio de $8,318 pesos. A continuaci√≥n se presenta una breve descripci√≥n de las variables.

| Variable             | Tipo     | Descripci√≥n                                                                                                                                                                                                                                  |
|---------------------------------------------------------------------|-----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Desc_Num             | Cont√≠nua | Precio (en Pesos Mexicanos) del seguro de autom√≥vil con cobertura amplia que cubre al autom√≥vil por 1 a√±o. Es la variable objetivo.                                                                                                                                                                                           |
| Modelo               | Nominal | El   a√±o del modelo del autom√≥vil cotizado. Los modelos de la base son de 2002 a 2021.                                                                                                                                                      |
| Moneda               | Nominal  | Identifica   la moneda en la que se cotiz√≥ el seguro:      USD - D√≥lares      MXN - Pesos Mexicanos.                                                                                                                                      |
| Segmento_R             | Nominal  | Variable creada para identificar el segmento del autom√≥vil cotizado. Los valores que puede tomar la variable son los   siguientes:      Auto Compacto      Auto Deportivo,      Auto Especial,      Auto Subcompacto,      Auto Uso M√∫ltiple y Camion Ligero de hasta 3.5 toneladas. |
| Elegible_UBER        | Nominal  | Identifica   si el autom√≥vil cotizado cumple los requisitos de 2021 para poder ser usado en la   plataforma de transporte privado UBER. Los valores que puede tomar son:         No o Si.                                                    |
| Agencia_Taller       | Nominal  | Identifica   si el autom√≥vil cotizado es de Taller o Agencia. Los valores que puede tomar   son: Taller y Agencia.                                                                                                                         |
| QC                   | Nominal  | Identifica   si el autom√≥vil tiene techo solar. Los valores que puede tomar son:      1 - Si tiene o 0 - No tiene.                                                                                                                         |
| Frenos               | Nominal  | Indica si el autom√≥vil tiene frenos con Anti Lock Braking System (ABS por sus siglas en ingl√©s). 1 - Si tiene, 0 - No tiene o Desconocido - No se sabe si los tiene.                                                                                                                                                                                                                       |
| Pasajeros_5          | Nominal  | Identifica   si el autom√≥vil cotizado es para 5 pasajeros o no. Los valores que puede tomar   son:      1 - Si o 0 - No.                                                                                                                        |
| Zona_volatilidad_Ord | Nominal  | Variable   creada para poder capturar la variabilidad del precio de seguro de un   autom√≥vil en funci√≥n del Municipio de cotizaci√≥n. Los valores que puede tomar son:      Baja, Media o Nula.                              |
| SA_siniestro         | Cont√≠nua | Suma   Asegurada del seguro de autom√≥vil.                                                                                                                                                                                                            |
| Estado               | Nominal  | Estado   donde se realiz√≥ la cotizaci√≥n.                                                                                                                                                                                                      |
| Tipo_Zona            | Nominal  | El   tipo de zona donde se realiz√≥ la cotizaci√≥n. Los valores que puede tomar   son:      Desconocido, Rural, Semiurbano o Urbano.                                                                                                 |
| Carroceria_R         | Nominal  | La   clasificaci√≥n revisada de la carrocer√≠a. Las posibles opciones son: Hatchback (HB), Minivan, Pick-Up, Sed√°n, Sport Utility Vehicle (SUV), Van y Otra (incluye Convertible, Coup√©, Estacas, Station Wagon, Panel y Cabina).                                                                                                                                                                                                         |
| Municipio_R          | Nominal  | Variable   creada para identificar si la cotizaci√≥n del asegurado pertenece a Zapopan,   Atizap√°n de Zaragoza, Guadalajara, Naucalpan de Ju√°rez, Toluca y Morelia.                                                                            |
                                                                                                          |
Table: Descripci√≥n de Variables

En los siguientes cap√≠tulos se describir√°n las variables, la raz√≥n por la que se agregaron al modelo y razonamiento detr√°s de la creaci√≥n de algunas variables indicadoras.

## 5.3 Variable Objetivo

La variable objetivo es el precio del seguro con cobertura ampl√≠a que se identifica en la base como "Desc_Num". La cobertura amplia protege contra: robo total, gastos m√©dicos a ocupantes, responsabilidad civil para bienes y responsabilidad civil para personas. La variable tiene el siguiente comportamiento.



```{r plot1, echo=FALSE, fig.align="center", fig.cap="Gr√°fica de Viol√≠n del Precio del Seguro", warning=TRUE}

ggplot(benchmark_model, aes(x = "", y = QUA_Desc_Num)) + 
  labs(x = "", y = "Precio del Seguro") + 
  geom_violin(trim = FALSE, fill = "gray") +
  geom_boxplot(width = 0.1) + 
  theme_classic() +
  scale_y_continuous(labels = scales::dollar_format())

```


Como se observa en la gr√°fica anterior la variable tiene un sesgo positivo (la mediana es menor que la media) y tiene cola una pesada que tambi√©n se observa en una distribuci√≥n Gamma. Adem√°s las cotizaciones tienen la siguiente distribuci√≥n de los cuantiles.

```{r, echo=FALSE, results = "hide"}
summary(benchmark_model$QUA_Desc_Num)
```

| M√≠nimo | Primer Cuartil | Mediana |  Media | Tercer Cuartil |  M√°ximo |
|:------:|:--------------:|:-------:|:------:|:--------------:|:-------:|
| \$3,475 |     \$6,548     |  \$7,970 | \$8,996 |     \$10,204    | \$29,993 |
Table: Estad√≠sticas del Precio de la Suma Asegurada

El seguro m√°s barato corresponde a un Chevrolet Chevy Modelo 2003 en Fort√≠n de las Flores y el m√°s caro corresponde a una Toyota Tacoma Modelo 2020 cotizado en Veracruz. Ambas cotizaciones tienen sentido ya que son veh√≠culos con diferente antiguedad y en ubicaciones muy diferentes. Adicionalmente, la distribuci√≥n de precios tiene una forma similar a una distribuci√≥in gamma.

La variable es adecuada al no tener un comportamiento inusual.

## 5.4 Variables Explicativas

En este cap√≠tulo se describir√°n las variables explicativas usadas para predecir el precio del seguro de autom√≥vil. Algunas variables son caracter√≠sticas del autom√≥vil y caracter√≠sticas del asegurado. Para todas las variables se hizo un an√°lisis con gr√°ficas de viol√≠n; sin embargo, en este trabajo s√≥lo se dejaron aquellas gr√°ficas que serv√≠an para poder identificar comportamientos particulares.


### 5.4.1 Modelo del Autom√≥vil

La variable Modelo (identificada como "Modelo" en la base) nos dice el a√±o del modelo autom√≥vil cotizado. A continuaci√≥n una gr√°fica comparando la relaci√≥n entre la variable objetivo y el modelo.


```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Distribuci√≥n del Modelo Respecto al Precio"}
ggplot(data = benchmark_model, aes(x = (Modelo), y = (QUA_Desc_Num))) +
  geom_point() + 
  labs(y = "Precio del Seguro", x = "Modelo") + 
  theme_classic() + 
  geom_smooth(mapping = aes(x = Modelo, y = (QUA_Desc_Num)), se = FALSE) + 
  theme_classic() + 
  scale_y_log10(labels = scales::dollar_format())
```


Existe una relaci√≥n creciente y exponencial entre la variable objetivo con el Modelo del auto. Es decir, entre m√°s nuevo es el modelo del autom√≥vil asegurado, m√°s cara es la cotizaci√≥n del seguro. Esta relaci√≥n se considera adecuada ya que los seguros de autom√≥vil son m√°s caros para modelos m√°s nuevos. Aunque el crecimiento no es lineal y la varianza va creciendo se va a usar ya que existe una relaci√≥n con el precio final y se considerar√° una transformaci√≥n logar√≠tmica.


### 5.4.2 Moneda

La variable se identifica como "Moneda" en la base. Clasifica si el seguro se cotiz√≥ originalmente en d√≥lares ($USD$) o en pesos mexicanos ($MXN$). Esto no impacta el precio final ya que todas las cotizaciones son en pesos mexicanos. Alrededor de 7.1% (1,195 datos de 16,942) de las cotizaciones fu√© hecha en d√≥lares; sin embargo, la siguiente gr√°fica muestra que el comportamiento en t√©rminos del precio final es diferente.

\newpage

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Moneda"}
ggplot(benchmark_model, aes(x = as.factor(Moneda), y = QUA_Desc_Num)) + 
    labs(x = "Moneda de la Cotizaci√≥n", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width = 0.1) + 
    theme_classic() + 
    scale_x_discrete(guide = guide_axis(angle = 45)) +
    scale_y_continuous(labels = scales::dollar_format())

nrow(benchmark_model)
table(benchmark_model$Moneda)
```

El comportamiento de las cotizaciones en pesos tiene un sesgo positivo con valores m√°s cercanos a 0. En comparaci√≥n con lo observado para las cotizaciones en d√≥lares que demuestran tener un comportamiento menos sesgado con una media y mediana m√°s parecidas as√≠ como estar m√°s alejadas del 0. Por lo que la variable discrimina el comportamiento del precio. Finalmente, el promedio de precios cotizados originalmente en d√≥lares es superior a aquellos cotizados en pesos mexicanos, por lo que existe una diferencia entre categor√≠as que ayudar√° en la predicci√≥n del precio.

Se consider√≥ agregar la variable al modelo ya que la categor√≠a discrimina bien el monto final del seguro.


### 5.4.3 Segmento

La variable identificada como "Segmento" en la base de datos representa el tipo de autom√≥vil cotizado. La siguiente gr√°fica muestra la distribuci√≥n de esta variable.

La variable "Segmento" presente en la base de datos corresponde a la clasificaci√≥n del tipo de autom√≥vil cotizado por el cliente. Esta variable permite agrupar los veh√≠culos seg√∫n sus caracter√≠sticas generales, como sed√°n, SUV, hatchback, entre otros. A continuaci√≥n, se presenta una gr√°fica que ilustra la distribuci√≥n de frecuencias de esta variable.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Distribuci√≥n de la Variable Segmento", fig.height = 3, fig.width = 5}
ggplot(data = benchmark_original_dt, aes(x = Segmento)) + labs(x = "", y = "N√∫mero de Cotizaciones") +
  geom_bar() + 
  theme_classic() +
  scale_x_discrete(guide = guide_axis(angle = 90)) + theme(
    axis.text.x = element_text(size = 6),  # Tama√±o del texto en el eje x
    axis.text.y = element_text(size = 7),  # Tama√±o del texto en el eje y
    axis.title.y = element_text(size = 6)  # Tama√±o del t√≠tulo del eje y
  )

benchmark_model <- benchmark_model[,`:=`(Segmento_R = {fifelse(Segmento %in% c("Camion Ligero Hasta 1.5", "Camion Ligero Hasta 3.5",
                                                            "Camion Mediano Hasta 7.5", "Camion Ligero Hasta 1.5", "Desconocido"), "Camion", 
                                            fifelse(Segmento %in% c("Auto Deportivo", "Auto Lujo", "Auto Subcompacto", "Auto Uso Multiple", "Auto Compacto"), "Auto Especial", Segmento))}
                                         )]

```

\newpage

Se observa que las categor√≠as "Cami√≥n Ligero Hasta 1.5", "Cami√≥n Ligero Hasta 7.5", "Auto Deportivo" y "Desconocido" representan menos del 5% del total de los datos, lo que indica que la variable presenta una distribuci√≥n desequilibrada entre sus categor√≠as. Se identific√≥ que las submarcas incluidas en la categor√≠a "Desconocido" tambi√©n est√°n presentes dentro de las submarcas de camiones ligeros. Por esta raz√≥n, se decidi√≥ reagrupar todas las categor√≠as relacionadas con camiones ligeros, incluyendo "Desconocido", en una sola categor√≠a denominada "Cami√≥n Ligero". Que tiene veh√≠culos como Ford F-150, Dodge Ram, y varios tipos de Pick Up.

De forma similar, se cre√≥ una nueva categor√≠a denominada "Auto", que agrupa todos los veh√≠culos del tipo sed√°n como Chevrolet Spark, Audi Q8 y varios tipos de SUV.

Estas nuevas categor√≠as forman parte de una nueva variable recodificada, denominada "Segmento_R". Dado que cada una de las nuevas categor√≠as presenta comportamientos distintos en relaci√≥n con el precio del seguro, se decidi√≥ utilizar esta variable en los modelos de estimaci√≥n.

### 5.4.4 Elegibilidad para UBER

Esta variable, identificada en la base de datos como "Elegibilidad_UBER", clasifica si el autom√≥vil cotizado cumple con los criterios establecidos por la plataforma UBER en 2021 para prestar servicio de transporte privado. Seg√∫n la informaci√≥n disponible en el sitio oficial de UBER, las caracter√≠sticas m√≠nimas que debe cumplir un veh√≠culo para ser considerado elegible son las siguientes:

+ No m√°s de 10 a√±os de antig√ºedad
+ Capacidad m√≠nima para 4 pasajeros
+ Tener cinturones de seguridad para todos los pasajeross
+ Frenos ABS y bolsas de aire
+ Aire acondicionado
+ Radio AM/ FM
+ Estar en buenas condiciones y sin da√±os est√©ticos
+ No tener ning√∫n emblema o calcoman√≠as comerciales

Alrededor del 32% de los autom√≥viles cotizados (5,338 datos de 16,942) no pueden ser usados para la aplicaci√≥n de transporte privado.

\newpage

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Elegibilidad de UBER"}
ggplot(benchmark_model, aes(x = as.factor(Elegible_UBER), y = QUA_Desc_Num)) + 
    labs(x = "Elegibilidad UBER", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width=0.1) + 
    theme_classic() +
  scale_y_continuous(labels = scales::dollar_format())

nrow(benchmark_model)
table(benchmark_model$Elegible_UBER)
```


Como se puede observar, los veh√≠culos que no cumplen con los criterios de elegibilidad para UBER presentan, en promedio, un precio de seguro menor en comparaci√≥n con aquellos que s√≠ son elegibles. Adem√°s, se aprecia una relaci√≥n positiva entre la elegibilidad para UBER y el precio del seguro. Esto resulta coherente, ya que los requisitos m√≠nimos exigidos por la plataforma (como el modelo reciente, buenas condiciones mec√°nicas y caracter√≠sticas de confort) tienden a estar asociados con veh√≠culos de mayor valor. A mayor valor del veh√≠culo, es esperable que el costo del seguro tambi√©n se incremente.

Por esta raz√≥n, la variable Elegibilidad_UBER se incluir√° en los modelos predictivos. No obstante, se reconoce la posible colinealidad con otras variables explicativas, dado que esta variable resume varias caracter√≠sticas del autom√≥vil. Aun as√≠, se decidi√≥ conservarla para no perder informaci√≥n relevante del perfil del veh√≠culo, y se evaluar√° su significancia estad√≠stica dentro de los modelos para determinar si debe mantenerse o eliminarse durante el proceso de ajuste.


### 5.4.5 Veh√≠culo de Agencia o de Taller

Esta variable se identifica en la base como "Agencia_Taller", indica si el autom√≥vil cotizado proviene de un taller o de una agencia. Del total de 17,053 registros, el 17% corresponde a veh√≠culos de agencia (2,729 observaciones), lo que sugiere que la variable se encuentra adecfuadamente distribuida entre sus categor√≠as.

Los autom√≥viles adquiridos en taller son autos m√°s antiguos, que se han reparado o que tienen desgaste, por lo que el costo de asegurarlo es menor. Por lo que se puede decir que esta variable es adecuada para poder predecir el comportamiento del precio del seguro y se decidi√≥ usar la variable.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Techo Solar"}

nrow(benchmark_model)
table(benchmark_model$Agencia_Taller)
```


### 5.4.6 Techo Solar

La variable se identifica como "QC". Esta variable identifica si el veh√≠culo tiene techo solar (llamado tambi√©n quemacocos). Toma el valor de $1$ si tiene esta caracter√≠stica y $0$ en otro caso. Alrededor del 70.31% (11,998 datos de 17,053) de los autom√≥viles no tienen techo solar.

\newpage


```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Techo Solar"}
ggplot(benchmark_model, aes(x = as.factor(QC), y = QUA_Desc_Num)) + 
    labs(x = "Tiene Techo Solar", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width=0.1) + 
    theme_classic() + scale_x_discrete(guide = guide_axis(angle = 45)) +
  scale_y_continuous(labels = scales::dollar_format())

nrow(benchmark_model)
table(benchmark_model$QC)
```

La distribuci√≥n de precios para veh√≠culos con techo solar es bimodal. Al hacer un prueba estad√≠stica t de comparaci√≥n de medias se obtiene lo siguiente:

```{r, echo=FALSE, message = FALSE, results = "hide"}
t.test(QUA_Desc_Num ~ QC, data = benchmark_model, var.equal = FALSE)
t.test(QUA_Desc_Num ~ QC, data = benchmark_model, var.equal = TRUE)
```

| Tipo de Prueba t para Medias   | p-value |
|:------------------------------:|:-------:|
| Asumiendo varianzas iguales    | < 0.1%  |
| Asumiendo varianzas desiguales | < 0.11% |
Table: Resultados de la Prueba Estad√≠stica


Dados los resultados de la prueba se concluye que existe una diferencia significativa en la media entre las categor√≠as analizadas. En particular, la presencia de un techo solar suele implicar un costo adicional en el veh√≠culo y es una caracter√≠stica com√∫n en autos de gama alta. Por lo tanto, se observa una relaci√≥n entre la presencia de techo solar y el precio del seguro. Dado que esta variable muestra una asociaci√≥n relevante con el objetivo del modelo, se decidi√≥ incluirla en el an√°lisis.


### 5.4.7 Frenos

Esta variable se identifica en la base como "Frenos", donde "1" identifica si el autom√≥vil tiene frenos tipo ABS (por sus siglas en ingl√©s Anti-Lock Brake System) y ayuda a identificar el tipo de frenos del autom√≥vil. Alrededor de 54% de los autos tienen frenos tipo ABS, y como la instalaci√≥n de ese tipo de frenos tiene un costo se espera que tengan un precio superior. Se decidi√≥ usar esa variable ya que captura el comportamiento del precio del seguro.


### 5.4.8 N√∫mero de Pasajeros del Autom√≥vil

La variable identificada en la base como "Pasajeros_5" es una variable dummy que identifica si el autom√≥vil cotizado es de 5 pasajeros. Alrededor del 14.6% (2,485 datos de 17,053) de los veh√≠culos cotizados no tienen la capacidad de tener 5 pasajeros por lo que la variable es balanceada. La variable se usa por que usualmente el n√∫mero de asientos permite identificar el uso del veh√≠culo y en consecuencia ayuda a predecir el precio.


### 5.4.9 Volatilidad de la Zona

Para la predicci√≥n del precio del seguro es importante considerar la ubicaci√≥n del asegurado ya que hay factores ex√≥genos al autom√≥vil como la delincuencia, tipo de calle, costo de legislaci√≥n entre otros que tienen impacto en el precio del seguro. Muchas compa√±√≠as de seguros al calcular el precio toman en cuenta la ubicaci√≥n (ya sea a nivel calle, municipio o c√≥digo postal) del asegurado ya que el nivel de riesgo no es uniforme a lo largo del pa√≠s. Por lo tanto se debe crear alguna variable que pueda capturar el nivel de riesgo de la ubicaci√≥n. Se considerar√° crear una variable que se llamar√° "Zona_volatilidad" para que clasifique la desviaci√≥n est√°ndar del precio de seguro por municipio. 

La siguiente gr√°fica es un mapa de calor que muestra un ejemplo de la desviaci√≥n est√°ndar del precio del seguro (que se llamar√° volatilidad) por municipio en funci√≥n de la submarca y que se contemple el n√∫mero de cotizaciones. La gr√°fica se hace con la intenci√≥n de presentar el comportamiento del municipio entre submarcas. Se restringi√≥ a aquellos municipios que tienen una desviaci√≥n est√°ndar mayor a 500 con m√°s de 20 cotizaciones para poder tener una mejor visualizaci√≥n.

```{r, echo=FALSE, results = "hide", fig.cap = "Mapa de Calor por Municipio y Submarca", fig.height = 5, fig.width = 6}

benchmark_train_municipio <- benchmark_model[, .(cotizacion_prom = mean(QUA_Desc_Num),
                                                 desv_estandard = sd(QUA_Desc_Num),
                                                 total_datos = .N),by = .(Municipio_D, Submarca_TP)]

median <- median(benchmark_train_municipio[desv_estandard >= 500 & total_datos > 20 & Municipio_D %!in% "Desconocido",]$desv_estandard)

ggplot(data = benchmark_train_municipio[desv_estandard >= 300 & total_datos > 20 & Municipio_D %!in% "Desconocido",], 
        aes(x = Municipio_D, y = Submarca_TP, size = total_datos)) + 
   geom_point(aes(color = desv_estandard)) + 
   scale_color_gradient2(low = "green", mid = "yellow", high = "red", midpoint = 3500) +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.key.size = unit(0.30, 'cm'), legend.title = element_text(size = 9)) + 
   labs(x = "Municipio", y = "Submarca", color = "Desv. Est√°ndard del\nPrecio del Seguro", size = "Total de Cotizaciones")


benchmark_train_municipio[,':='(Zona_volatilidad = fifelse(is.na(desv_estandard) | desv_estandard == 0, "Nula",
                                                           fifelse(0 < desv_estandard & desv_estandard <= 300, "Baja",
                                                                   fifelse(300 < desv_estandard & desv_estandard <= 1300, "Media", "Alta"))),
                                Llave = paste0(Municipio_D,"-",Submarca_TP))]


zona_clasif <- unique(benchmark_train_municipio[,c("Llave", "Zona_volatilidad")])

benchmark_model[, ':='(Llave = paste0(Municipio_D,"-",Submarca_TP))]

benchmark_model[zona_clasif, on = 'Llave', Zona_volatilidad := i.Zona_volatilidad]

benchmark_model[, ':='(Zona_volatilidad_Ord = factor(Zona_volatilidad, levels = c("Nula", "Baja", "Media", "Alta")))]

```

Como se observa en la gr√°fica anterior, existen varias submarcas que acumulan una alta volatilidad en el precio de su seguro dependiendo del municipio. Por ejemplo, dentro del municipio de Guadalajara hay mucha volatilidad en el precio de seguro de autom√≥vil para la Chevrolet Suburban (tiene una desviaci√≥n est√°ndar arriba de 4 mil pesos dentro del municipio y menos de 50 cotizaciones). Este resultado puede deberse principalmente al alto √≠ndice de criminalidad en el estado de Jalisco ya que de acuerdo al archivo "Sistema Estad√≠stico del Sector Asegurador del Ramo Autom√≥viles" en ese estado durante 2021 se observ√≥ que el 0.97% de los veh√≠culos asegurados eran robados. La cifra est√° dentro de los estados con mayor √≠ndice de robo en M√©xico y esta por encima del promedio nacional del 2021 (0.46%). Por lo que es probable que el seguro para ese estado tenga un gran variabilidad en el municipio donde se encuentra el asegurado. Adicionalmente, en 2021 en Puebla se observa que el 6.1% de los autos asegurados tiene reclamaci√≥n de Responsabilidad Civil lo que lo ubica dentro de los 10 estados con mayores reclamaciones. 

En comparaci√≥n, la gr√°fica nos muestra que en la alcald√≠a de Benito Ju√°rez en la Ciudad de M√©xico se tiene m√°s cotizaciones (m√°s de 50) del Honda CR-V pero se observa una menor variabilidad en el precio (menor a $2,000). Esto puede ser resultado de que esa alcald√≠a se encuentra de los estados con menor reporte de robos de autom√≥vil de ese a√±o.

Ya que √©ste resultado parece coincidir con lo observado en el sector asegurador y parece discriminar adecuadamente la variabildad del precio del seguro por municipio se crear√° una variable haciendo uso de √©sta informaci√≥n.

Para poder usar la variabilidad por municipio se decidi√≥ capturar los cambios entre municipios es decir clasificar los municipios en funci√≥n de la desviaci√≥n est√°ndar. La variable se llam√≥ "Zona de Volatilidad" que clasifica la volatilidad de la siguiente forma:

| Categor√≠a | Desviaci√≥n Est√°ndar |
|:---------:|:-------------------:|
|    Nula   |          0          |
|    Baja   |       (0, 300]      |
|   Media   |     (300, 1300]     |
|    Alta   |       (1300, $+\infty$]      |
Table: Categor√≠as de la Volatilidad de las Zonas

Los cortes se hicieron de acuerdo a la variabildad obtenida al agrupar los municipios de manera ascendente con las submarcas de veh√≠culos. As√≠ mismo, se escogi√≥ una categor√≠a llamada "Nula" para aquellos municipios donde s√≥lo hay 1 cotizaci√≥n o su municipio no tiene variabilidad.

Ya que el objetivo del modelo es poder predecir el precio del seguro de autom√≥vil de acuerdo a las caracter√≠sticas del autom√≥vil y de la ubicaci√≥n del asegurado; entonces, en la aplicaci√≥n del modelo existir√°n algunas combinaciones de municipio con submarca de veh√≠culo que no han sido cotizados. Por ejemplo, si se quiere estimar el precio del seguro de autom√≥vil para un asegurado en alg√∫n municipio que no se encontraba en la base de estimaci√≥n el modelo no podr√° hacer alguna inferencia. Para corregir esto se clasificar√° autom√°ticamente como Zona de Volatildad "Media" a estos municipios no catalogados ya que en promedio los municipio tienen una zona de volatildad entre 300 y 1300.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Zona de Volatidad"}
ggplot(benchmark_model, aes(x = as.factor(Zona_volatilidad_Ord), y = QUA_Desc_Num)) + 
    labs(x = "Categor√≠a de Zona de Volatilidad", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width=0.1) + 
    theme_classic() + scale_x_discrete(guide = guide_axis(angle = 45)) +
    scale_y_continuous(labels = scales::dollar_format())
```

\newpage

Como se observa en la gr√°fica, la categor√≠a de la variable si puede discernir entre los diferentes niveles de riesgo y observamos lo siguiente:

+ La categor√≠a Nula tiene una distribuci√≥n sesgada pero observamos un comportamiento similar a la distribuci√≥n de precios general en t√©rminos de varianza. 
+ La categor√≠a Baja tiene un distribuci√≥n cuyos precios en promedio inferior a las dem√°s con un comportamiento multimodal y una varianza baja.
+ La categor√≠a Media tiene precios que en promedio est√°n por arriba que la categor√≠a Baja; sin embargo, tiene mayor varianza con un comportamiento bimodal.
+ La categor√≠a Alta es la que tiene en promedio mayor costo en los precios del seguro, tiene una distribuci√≥n mesoc√∫rtica, tiene mayor varianza y es una distribuci√≥n m√°s estable.

Aunque la categor√≠a Nula y Alta tienen mayor n√∫mero de outliers esta variable se usar√° ya que captura el nivel de riesgo por municipio y clasifica adecuadamente los precios de seguros de autom√≥vil.

### 5.4.10 Suma Asegurada

La variable de Suma Asegurada (identificada como "SA_Siniestro" en la base) identifica la exposici√≥n del seguro. Abajo se encuentra una gr√°fica que muestra la relaci√≥n entre esta variable y la variable objetivo.

\newpage


```{r, echo=FALSE, message = FALSE, fig.align = "center", fig.cap = "Gr√°fica de Correlaci√≥n Precio y Suma Asegurada"}
ggplot(data = benchmark_model, aes(x = SA_siniestro, y = QUA_Desc_Num)) +
    geom_point() + 
    labs(y = "Precio de Seguros", x = "Suma Asegurada") + 
    theme_classic() + 
    geom_smooth(mapping = aes(x = SA_siniestro, y = QUA_Desc_Num), se = FALSE, color = "blue") + geom_abline(color = "green", intercept = 0, slope = 1) + 
    stat_cor(aes(label = after_stat(r.label)),
             method = "pearson", 
             label.x = 3, 
             label.y = 30, 
             cor.coef.name = "r") +
    scale_x_continuous(labels = scales::dollar_format()) +
    scale_y_continuous(labels = scales::dollar_format())
```
Como se observa en la gr√°fica, la correlaci√≥n es superior al 66%, lo cual indica que la relaci√≥n lineal entre la suma asegurada y el precio del seguro es alta. La l√≠nea verde es la identidad y la l√≠nea azul es de regresi√≥n (usando m√©todo de m√≠nimos cuadrados ordinarios). Se concluye que existe una relaci√≥n positiva entre ambas variables lo cual tiene sentido ya que el riesgo de un autom√≥vil es fuertemente impactado por su costo. Adem√°s, conforme aumenta la suma asegurada aumenta la dispersi√≥n del precio del seguro ya que conforme aumente el costo del veh√≠culo aumenta el riesgo y otros factores influyen en el riesgo. Es decir, una suma asegurada de 250 mil pesos no impacta mucho las caracter√≠sticas del asegurado o del veh√≠culo, pero el costo de un seguro cuya suma asegurada es mayor a 500 mil pesos puede ser m√°s sensible al modelo del autom√≥vil o incluso a la ubicaci√≥n del asegurado.

Adicionalmente, se analizar√° la distribuci√≥n de la suma asegurada.


```{r, echo = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n de la Suma Asegurada"}
ggplot(benchmark_model, aes(x = "", y = SA_siniestro)) + 
  labs(x = "", y = "Suma Asegurada") + 
  geom_violin(trim = FALSE, fill = "gray") +
  geom_boxplot(width = 0.1) +
  ggtitle("") +
  theme_classic() +
  scale_y_continuous(labels = scales::dollar_format())
```

\newpage

Se observa que se tiene una distribuci√≥n multimodal.

```{r, echo=FALSE, results = "hide"}
#benchmark_model <- benchmark_model[1500000 >= SA_siniestro]
```

Adicionalmente, se evaluar√° si es necesario usar un t√©rmino polin√≥mico o una transformaci√≥n logar√≠tmica para poder tener un mejor ajuste de la suma asegurada.


```{r, echo=FALSE, message = FALSE, fig.align = "center", fig.cap = "Correlaci√≥n Suma Asegurada T√©rmino Cuadrado y Logar√≠tmico"}
graph_1 <- ggplot(data = benchmark_model, aes(x = SA_siniestro, y = QUA_Desc_Num)) +
    geom_point() + 
    labs(y = "Precio de Seguros (en miles)", x = "Suma Asegurada \n (en miles)") + 
    theme_classic() + 
    stat_smooth(method='lm', formula = y ~ poly(x, degree = 2), se = FALSE) + 
    stat_cor(aes(label = after_stat(r.label)),
             method = "pearson", cor.coef.name = "r") +
  scale_x_continuous(labels = scales::dollar_format(scale = 0.001), guide = guide_axis(angle = 90)) +
  scale_y_continuous(labels = scales::dollar_format(scale = 0.001)) 

graph_2 <- ggplot(data = benchmark_model, aes(x = log(SA_siniestro), y = log(QUA_Desc_Num))) +
    geom_point() + 
    labs(y = "Logaritmo Precio de Seguros", x = "Logaritmo de \n Suma Asegurada") + 
    theme_classic() + 
    stat_smooth(method='lm', formula = y ~ poly(x, degree = 2), se = FALSE) + 
    stat_cor(aes(label = after_stat(r.label)),
             method = "pearson", cor.coef.name = "r")

plot_grid(graph_1, graph_2)
```


En la gr√°fica de la izquierda la l√≠nea azul representa la regresi√≥n polinomial de grado 2, pero no se ve que la relaci√≥n entre variables requiera usar este tipo de regresi√≥n ya que el coeficiente de correlaci√≥n (67%) es inferior en 3% y s√≥lo parece tener una relaci√≥n lineal. Sin embargo, en la gr√°fica de la derecha se observa que la transformaci√≥n logar√≠tmica es m√°s adecuada y tiene menor dispersi√≥n que usar una transformaci√≥n lineal. Por lo tanto, por principio de parsimon√≠a primero se considerar√° usar la suma asegurada de manera lineal en el modelo y despu√©s se har√° una transformaci√≥n logar√≠tmica para identificar cual es el mejor ajuste.

Finalmente, ya que se comprob√≥ la relaci√≥n lineal positiva entre la Suma Asegurada y el precio del seguro se usar√° √©sta variable en el modelo. 

### 5.4.11 Estado

La variable identifica el Estado de vivienda del potencial asegurado. As√≠ como se cre√≥ una variable para poder capturar aquellos factores ex√≥genos que pueda impactar el c√°lculo del precio se decidi√≥ usar una variable m√°s agregada que refleje el riesgo a nivel estado.

En general cada estado tiene un comportamiento diferente. Pero, el Estado de M√©xico (llamado en los datos como M√©xico) y Jalisco tienen mayor varianza. Adicionalmente, el estado de Guanajuato tiene menor varianza que el resto. Finalmente, se decidi√≥ usar la variable ya que es informaci√≥n adicional respecto a la ubicaci√≥n geogr√°fica del asegurado que se puede usar en el modelo, y puede dar informaci√≥n general sobre el comportamiento de los precios en el pa√≠s. Adem√°s, con el an√°lisis de significancia se evaluar√° la permanencia de la variable.

\newpage

### 5.4.12 Tipo de Zona

La variable Tipo de Zona se identifica en la base como "Tipo_Zona_R" y es el tipo de suelo de la direcci√≥n donde se realiz√≥ la cotizaci√≥n. Se clasifica de la siguiente manera:

+ Rural (10.3%).
+ Urbano y Semiurbano (77.3%).
+ Desconocido (12.4%).

La variable tiene la siguiente distribuci√≥n:

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Zona"}

benchmark_model <- benchmark_model[,`:=`(Tipo_Zona_R = {fifelse(Tipo_Zona %in% c("Urbano", "Semiurbano"), "Urbano", Tipo_Zona)})]

ggplot(benchmark_model, aes(x = as.factor(Tipo_Zona_R), y = QUA_Desc_Num)) + 
    labs(x = "Tipo de Zona", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width=0.1) + 
    theme_classic() + scale_x_discrete(guide = guide_axis(angle = 45)) +
  scale_y_continuous(labels = scales::dollar_format())

nrow(benchmark_model)
table(benchmark_model$Tipo_Zona)

t.test(benchmark_model[Tipo_Zona_R == "Urbano"]$QUA_Desc_Num,
       benchmark_model[Tipo_Zona_R == "Rural"]$QUA_Desc_Num, 
       mu = 0)

t.test(benchmark_model[Tipo_Zona_R == "Urbano"]$QUA_Desc_Num,
       benchmark_model[Tipo_Zona_R == "Desconocido"]$QUA_Desc_Num, 
       mu = 0)

t.test(benchmark_model[Tipo_Zona_R == "Rural"]$QUA_Desc_Num,
       benchmark_model[Tipo_Zona_R == "Desconocido"]$QUA_Desc_Num, 
       mu = 0)

nrow(benchmark_model)
table(benchmark_model$Tipo_Zona_R)
```
De la gr√°fica se puede concluir que el tipo de suelo Desconocido es menos sesgada en comparaci√≥n con las otras categor√≠as. As√≠ mismo, la categor√≠a Rural tiene un sesgo positivo pero tiene un comportamiento m√°s estable que el Urbano cuya distribuci√≥n tiene evidencia de que los precios se acumulan en diferentes rangos. Para descartar que todas las categor√≠as tengan la misma media se hizo una prueba estad√≠stica t para identificar si existe evidencia para asumir que las medias son diferentes. El resultado obtenido fue que entre las 3 categor√≠as se tiene un $p-value$ inferior a 1% en todas las pruebas; por lo tanto, hay evidencia para asumir que las 3 categor√≠as tienen diferente media y pueden ayudar a discriminar el precio del seguro. Finalmente, cuando el suelo es urbano en promedio el precio del seguro es mayor al del suelo Rural. Este efecto puede ser producto de que hay m√°s cotizaciones donde el suelo es Urbano donde los autom√≥viles son m√°s usados lo cual eleva su nivel de riesgo.

Ya que el tipo de suelo captura el comportamiento del precio del seguro se decidi√≥ agregar la variable.

\newpage

### 5.4.13 Carrocer√≠a

Esta variable identifica el tipo de carrocer√≠a del veh√≠culo cotizado y se identifica en la base como "Carroceria_R".



```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Gr√°fica de Viol√≠n por Carrocer√≠a"}
ggplot(benchmark_model, aes(x = as.factor(Carroceria_R), y = QUA_Desc_Num)) + 
    labs(x = "Tipo de Carrocer√≠a", y = "Precio del Seguro") + 
    geom_violin(trim = FALSE, fill = "gray") +
    geom_boxplot(width=0.1) + 
    theme_classic() + scale_x_discrete(guide = guide_axis(angle = 45)) +
  scale_y_continuous(labels = scales::dollar_format())
```
Como se observa en la gr√°fica la distribuci√≥n de precios del seguro var√≠a entre el tipo de carrocer√≠a. Por ejemplo, la carrocer√≠a SUV es bimodal con poca varianza, en comparaci√≥n con la carrocer√≠a OTROS que tiene m√°s varianza y en promedio tiene el costo m√°s alto de precios. Adicionalmente, la variable HB es la que tiene los menores costos en promedio.

La variable al poder discriminar adecuadamente el precio del seguro de auto, se decidi√≥ agregar al modelo.


### 5.4.14 Municipios Especiales

Como se menciona en cap√≠tulos anteriores, el tipo de zona del asegurado tiene un impacto en el precio. Ya se construy√≥ una variable que captura la variabilidad de los precios a nivel municipio. Pero no hemos hecho alguna variable que identifique si el asegurado pertenence a un municipio de la misma forma en la que se us√≥ el estado del asegurado y su tipo de suelo. Esto fu√© por que la variable Municipio est√° muy desbalanceada.

Por eso se propone crear una variable que identifique si el asegurado se encuentra en alg√∫n municipio cuya variabilidad sea particularmente alta. Se llamar√° en la base "Municipio_Riesgo" y tendr√° la etiqueta de "$1$" si pertenece a un municipio especial y "$0$" en otro caso.

\newpage

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.height = 5, fig.width = 6, fig.cap = "Promedio de Precio por Municipio y su Desviaci√≥n Est√°ndard"}
benchmark_model_municipio <- benchmark_model[, .(cotizacion_prom = mean(QUA_Desc_Num) ,desv_estandard = sd(QUA_Desc_Num),
                                                 total_datos = .N, cv = sd(QUA_Desc_Num) * 100 / mean(QUA_Desc_Num)), by =  .(Municipio_D)]

ggplot(benchmark_model_municipio[desv_estandard >= 0 & total_datos > 150,], aes(x = reorder(as.factor(Municipio_D), -desv_estandard), y = cotizacion_prom)) + 
    labs(x = "Municipio", y = "Precio promedio") + geom_bar(stat="identity") + geom_errorbar(aes(x=as.factor(Municipio_D), ymin=cotizacion_prom-desv_estandard, ymax=cotizacion_prom+desv_estandard)) +
    theme_classic() + scale_x_discrete(guide = guide_axis(angle = 45)) +
  scale_y_continuous(labels = scales::dollar_format())

benchmark_model <- benchmark_model[,`:=`(Municipio_Riesgo = fifelse(Municipio_D %in% c("ZAPOPAN", "ATIZAP√ÅN DE ZARAGOZA", "GUADALAJARA", "NAUCALPAN DE JUAREZ", "TOLUCA", "MORELIA", "TORRE√ìN"), 1, 0))]

benchmark_model <- benchmark_model[,`:=`(Submarca_TP_R = fifelse(Submarca_TP %in% c("OTROS-SUV", "SEAT-IBIZA", "MAZDA-MAZDA 3", "JEEP-GRAND CHEROKEE", "HONDA-CIVIC", "HONDA-HR-V", "TOYOTA-HILUX"), 1, 0))]

table(benchmark_model$Municipio_Riesgo)/nrow(benchmark_model) * 100
```

Los municipios con una mayor variabilidad (identificada por las lineas negras) respecto a su precio promedio con cotizaciones mayores a 150 son:

+ Zapopan
+ Atizap√°n de Zaragoza
+ Guadalajara
+ Naucalpan de Ju√°rez
+ Toluca
+ Morelia
+ Torre√≥n

Los municipios de arriba tienen una mayor volatilidad con respecto al resto por lo que se decidi√≥ crear la variable que se identificar√° en la base como "Municipio_Riesgo". Para esta variable se tiene que el 15.54% de las cotizaciones pertenece a alguno de estos municipios por lo que no es desbalanceada. La variable se incluy√≥ ya que puede ser adecuada para predecir el precio del seguro.

\newpage


## 5.5 Preparaci√≥n de Modelos

Para la elaboraci√≥n de los modelos se dividieron los datos en 2 partes:

+ El 80% de los datos se usar√°n para entrenar el modelo
+ El 20% de los datos restantes para validarlo

Para la validaci√≥n se usar√°n los par√°metros obtenidos durante el entrenamiento del modelo y se usar√°n los datos de validaci√≥n para estimar la diferencia entre el precio del seguro estimado contra el precio del seguro real. Esta comparaci√≥n es importante ya que nos permite obtener un grado de error del modelo cuando se usa con datos los cuales no fueron usados para estimar el par√°metro, y as√≠ obtener una medida adecuada de su utilidad.

Para poder tener una mejor comparaci√≥n entre los modelos se decidi√≥ estimar del de menor complejidad al mayor, por lo que se usar√°n las siguientes 3 metodolog√≠as:

+ Modelo Lineal
+ Modelo Lineal Generalizado
+ XGradient Boosting

El siguiente cap√≠tulo describir√° la forma de evaluar las metodolog√≠a as√≠ como las m√©tricas finales de comparaci√≥n.

## 5.6 Estimaci√≥n de los Modelos

Como se ha mencionado anteriormente, en este cap√≠tulo se har√° la estimaci√≥n de los modelos. Se comenzar√° con las metodolog√≠as m√°s usuales y m√°s usadas que son los Modelos Lineales y Modelos Lineales Generalizados (usando regresi√≥n Gamma). Despu√©s de esas estimaciones se preparar√° la t√©cnica de XGradient Boosting.

Aunque las m√©tricas comparativas entre cada modelo se describieron en el cap√≠tulo anterior se decidi√≥ hacer an√°lisis adicionales en cada modelo. Por ejemplo, para el modelo lineal se har√° el an√°lisis de sus supuestos. Esto se hace con la finalidad de tener el mejor modelo para comparar.


### 5.6.1 Modelo Lineal

Para el modelo lineal se us√≥ la funci√≥n $lm$ de R. Como se mencion√≥ en cap√≠tulos anteriores se ajustar√° el modelo lineal y primero se evaluar√° si todas las variables fueron significativas.

```{r, echo=FALSE, message = FALSE, results = "hide"}

# Se divide la tabla
set.seed(123)
train <- sample(nrow(benchmark_model), round(0.8 * nrow(benchmark_model)), replace = FALSE)
benchmark_train <- benchmark_model[train, ]
benchmark_validate <- benchmark_model[-train, ]
#benchmark_validate[, Zona_volatilidad_Ord := "Media"]


model_1_train <- lm(QUA_Desc_Num ~ Modelo + Moneda + Segmento_R + Elegible_UBER + Agencia_Taller + QC + Frenos +
                                   Pasajeros_5 + Zona_volatilidad_Ord + SA_siniestro + Estado + 
                                   Tipo_Zona_R + Municipio_Riesgo + Marca_TP_R + Carroceria_R,
                                   data = benchmark_train)
summary(model_1_train)

```

La estimaci√≥n lineal se obtuvo una $R^2-ajustada$ de 77% y las siguientes variables no fueron estad√≠sticamente significativas:

|              Variable               |   p-valor     |
|:---------------------------:|:------:|
| **Zona Volatilidad-"Baja"** | 50% |
| **Carroceria-"SEDAN"** | 23.32% |

Table: An√°lisis de Permanencia de Variables

Del resumen del modelo se obtuvo que la categor√≠a "Zona Volatildad Baja", "Auto Uso M√∫ltiple", y "Carroceria-"SEDAN"" no son significativas. Sin embargo, las variables con m√°s de una categor√≠a y que s√≥lo 1 de ellas no fue significativas se conservar√°n ya que se desea preservar en el modelo el mayor n√∫mero de caracter√≠sticas del autom√≥vil o del asegurado. Finalmente, al tener una $R^2-ajustada$ de 77% indica que el modelo explica aproximadamente m√°s de 3 cuartas partes de la varianza (o que el modelo es 77% mejor que el promedio) lo cual es un ajuste adecuado.

\newpage

Procedemos a hacer el an√°lisis de los supuestos de la regresi√≥n.


```{r, echo=FALSE, message = FALSE, fig.height=5, fig.width=6, fig.cap = "An√°lisis de Supuestos del Modelo Lineal"}

# Se divide la tabla
par(mfrow = c(2, 2))
plot(model_1_train)

```

De las gr√°ficas anteriores se observa que:

+ No se observa independencia entre los residuos y las variables explicativas, ya que los residuos tienden a aumentar a medida que lo hacen los valores ajustados. Esto indica que no se cumple el supuesto de homocedasticidad, lo cual puede afectar la validez de la predicci√≥n del modelo.
+ Los residuos del modelo no siguen una distribuci√≥n Normal; sin embargo, su distribuci√≥n es bastante sim√©trica.
+ Se observan algunos outliers.
+ No se observa evidencia de varianza constante.

Dado el comportamiento de la gr√°fica, no se hacen pruebas de hip√≥tesis para verificar las conclusiones.

\newpage

As√≠ mismo al calcular las m√©tricas de error en la base de validaci√≥n se obtiene lo siguiente:


```{r, echo=FALSE, message = FALSE, results = "hide"}

predict_model_1 <- predict(model_1_train, benchmark_validate[,c("Modelo", "Moneda", "Segmento_R", 
                                                                "Elegible_UBER","Agencia_Taller",
                                                                "QC","Estado", "Frenos", "Tipo_Zona_R",
                                                                "Pasajeros_5", "Zona_volatilidad_Ord", "SA_siniestro",
                                                                "Frenos", "Municipio_Riesgo", "Marca_TP_R", "Carroceria_R")])

dif_abs_model_1 <- mean(abs(predict_model_1 - benchmark_validate$QUA_Desc_Num))
dif_porc_model_1 <- mean(abs((predict_model_1 - benchmark_validate$QUA_Desc_Num)/benchmark_validate$QUA_Desc_Num))
eam_model_1 <- sqrt(mean((predict_model_1 - benchmark_validate$QUA_Desc_Num) ^ 2))

dif_abs_model_1
dif_porc_model_1
eam_model_1

```
| EPAM   | EAM    | ECM    |
|:------:|:------:|:------:|
| 13.42% | \$1,231 | \$1,835 |
Table: M√©tricas de Validaci√≥n para el Modelo Lineal


De los resultados obtenidos podemos concluir que el modelo lineal se separa del precio real del seguro de autom√≥vil con cobertura amplia en alrededor del 13.88% que representa alrededor de $\$1,231$. Adem√°s, el $ECM$ indica que en promedio el modelo tiene una desviaci√≥n de $\$1,835$ de los datos reales.

Finalmente procedemos a hacer un an√°lisis sobre los residuos estimados.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Correlaci√≥n Valores Reales y Estimados"}

plot(predict_model_1, benchmark_validate$QUA_Desc_Num, 
     xlab = "Valores Estimados (Base Validaci√≥n)", 
     ylab = "Valores Reales", xaxt = 'n', yaxt = 'n')
abline(0,1)
axis(1, at = pretty(predict_model_1), labels = paste0("$", pretty(predict_model_1)), las = 0.5)
axis(2, at = pretty(benchmark_validate$QUA_Desc_Num), labels = paste0("$", pretty(benchmark_validate$QUA_Desc_Num)), las = 0.5) 
```



La gr√°fica hace una comparaci√≥n entre los valores estimados contra los valores reales de la base de validaci√≥n. Se observa que el modelo crea la relaci√≥n lineal; sin embargo, existe una alta variabilidad entre los resultados as√≠ mismo entre m√°s grande los valores estimados se observa mayor separaci√≥n entre el precio real del seguro contra el estimado. 

Como se mencion√≥ en cap√≠tulos anteriores, se buscar√° tener un mejor resultado al transformar logaritmicamente la variable dependiente y la Suma Asegurada de la variable independiente para poder tener un modelo con menos varianza en los residuos. Se usar√°n las mismas variables.

```{r, echo=FALSE, message = FALSE, results = 'hide'}

model_1_train_log <- lm(Log_QUA_Desc_Num ~ Modelo + Moneda + Segmento_R + Elegible_UBER + Agencia_Taller + QC + Frenos +
                                           Pasajeros_5 + Zona_volatilidad_Ord + Log_Siniestro_SA + Estado + 
                                           Tipo_Zona_R + Municipio_Riesgo + Marca_TP_R + Carroceria_R,
                         data = benchmark_train)

summary(model_1_train_log)
```

Al estimar el modelo con transformaci√≥n logar√≠tmica se obtuvo una $R^2-ajustada$ de 81% y las siguientes variables no fueron estad√≠sticamente significativas:

\newpage

|             Variable                |   p-valor     |
|:---------------------------:|:------:|
| **Frenos-"Desconocido"** | 30.6% |
Table: An√°lisis de Permanencia de Variables


Comparado con el modelo sin transformaci√≥n logar√≠tmica podemos concluir que existe una mejora en la estimaci√≥n ya que tenemos una m√©trica $R^2-ajsutada$ mayor y s√≥lo tres variables no son significativas.

Analizando el modelo de la regresi√≥n con transformaci√≥n logar√≠tmica obtenemos lo siguiente.

```{r, echo=FALSE, message = FALSE, fig.height=5, fig.width=6, fig.cap = "An√°lisis de Supuestos del Modelo Lineal"}

# Se divide la tabla
par(mfrow = c(2, 2))
plot(model_1_train_log)
```

Como se observa en la gr√°ficas anteriores se observa que:

+ Los residuos no siguen una distribuci√≥n Normal, aunque es muy sim√©trica.
+ Se cumple el supuesto de independencia (variables son independientes de los residuos).
+ No se observan m√°s que 3 posibles outliers.
+ Hay evidencia que el modelo tiene varianza constante.

Dado el comportamiento de la gr√°fica, no se hacen pruebas de hip√≥tesis para verificar las conclusiones.

Volveremos a calcular las m√©tricas de error se obtiene lo siguiente.

```{r, echo=FALSE, message = FALSE, results = "hide"}
predict_model_1_log <- predict(model_1_train_log, benchmark_validate[,c("Modelo", "Moneda", "Segmento_R", 
                                                                "Elegible_UBER","Agencia_Taller",
                                                                "QC","Estado", "Frenos", "Tipo_Zona_R",
                                                                "Pasajeros_5", "Zona_volatilidad_Ord", "Log_Siniestro_SA",
                                                                "Frenos", "Municipio_Riesgo", "Marca_TP_R", "Carroceria_R")])


dif_abs_model_1_log <- mean(abs(exp(predict_model_1_log) - benchmark_validate$QUA_Desc_Num))
dif_porc_model_1_log <- mean(abs((exp(predict_model_1_log) - benchmark_validate$QUA_Desc_Num)/benchmark_validate$QUA_Desc_Num))
eam_model_1_log <- sqrt(mean((exp(predict_model_1_log) - benchmark_validate$QUA_Desc_Num) ^ 2))

dif_abs_model_1_log
dif_porc_model_1_log
eam_model_1_log
```

| EPAM   | EAM    | ECM    |
|:------:|:------:|:------:|
| 11.80% | \$1,136 | \$1,764 |
Table: M√©tricas de Validaci√≥n para el Modelo Lineal con Transformaci√≥n Logar√≠tmica

De los resultados obtenidos podemos concluir que el modelo lineal se separa del precio real del seguro de autom√≥vil con cobertura amplia en alrededor del 11.8% que representa alrededor de $\$1,136$. Adem√°s, el $ECM$ indica que en promedio el modelo tiene una desviaci√≥n de $\$1,764$ de los datos reales. La transformaci√≥n logar√≠tmica no aumenta de manera significativa el poder predictivo del modelo. Sin embargo, ofrece un mejor ajuste en t√©rminos de $R^2-ajustada$ y se logra cumplir el supuesto de independencia.

Finalmente procedemos a hacer un an√°lisis sobre los residuos estimados.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Correlaci√≥n Valores Reales y Estimados"}
plot(exp(predict_model_1_log), benchmark_validate$QUA_Desc_Num, 
     xlab = "Valores Estimados (Base Validaci√≥n)", 
     ylab = "Valores Reales", xaxt = 'n', yaxt = 'n')
abline(0,1)
axis(1, at = pretty(exp(predict_model_1_log)), labels = paste0("$", pretty(exp(predict_model_1_log))), las = 0.5)
axis(2, at = pretty(benchmark_validate$QUA_Desc_Num), labels = paste0("$", pretty(benchmark_validate$QUA_Desc_Num)), las = 0.5) 
```
De manera similar al modelo sin transformaci√≥n existe una relaci√≥n lineal entre la estimaci√≥n con los valores reales y los estimados, pero los valores estimados m√°s grandes siguen teniendo mayor variabilidad con el valor real.

El modelo lineal sin transformaci√≥n es heterocedastico y no hay evidencia significativa de que sus residuos provengan de una distribuci√≥n Normal con media 0. Sin embargo, el modelo con transformaci√≥n logar√≠tmica cumple con los mismos supuestos que el modelo sin transformaci√≥n y tiene una $R^2-ajustada$ superior lo que nos indica que explica m√°s la varianza del precio del seguro de autom√≥vil. Finalmente, al hacer una comparaci√≥n con las m√©tricas de validaci√≥n observamos lo siguiente:

| Modelo                     | EAM    | EPAM     | ECM     |
|:--------------------------:|:-------:|:-------:|:-------:|
| Sin Transformaci√≥n         | \$1,231 |  13.42% | \$1,835 |
| Transformaci√≥n Logar√≠tmica | \$1,136 | 11.80%  | \$1,764 |
Table: Comparativa de M√©tricas de Validaci√≥n

De las m√©tricas de error se concluye que el modelo con mayor poder predictivo en promedio es el que estima el precio del seguro del autom√≥vil de manera logar√≠tmica. Al hacer una comparaci√≥n usando la m√©trica del coeficiente de informaci√≥n bayesiano (CIB) se obtiene lo siguiente (esa m√©trica se us√≥ ya que penaliza el n√∫mero de variables):


```{r, echo=FALSE, message = FALSE, results = "hide"}
BIC(model_1_train)
BIC(model_1_train_log)

```


| Modelo                     | CIB       |
|:--------------------------:|:---------:|
| Sin Transformaci√≥n         | 242, 431  |
| Transformaci√≥n Logar√≠tmica | -11, 415 |
Table: Comparativa de Coeficientes de Informaci√≥n


De acuerdo a √©sta m√©trica concluimos que el modelo con mejor ajuste es el que transforma logar√≠tmicamente la variable dependiente y ya que nos estamos enfocando en obtener un modelo que tenga un poder predictivo superior concluimos que se usar√° el modelo con transformaci√≥n logar√≠tmica para poder compararlo con el resto de propuestas metodol√≥gicas.


### 5.6.2 Modelo Lineal Generalizado

Para el modelo lineal se us√≥ la funci√≥n $glm$ de R con una distribuci√≥n Gamma y la liga identidad. La funci√≥n Gamma se seleccion√≥ ya que los precios son positivos, tiene un sesgo similar y es una distribuci√≥n muy usada en el √°rea de los seguros. Como se mencion√≥ en cap√≠tulos anteriores se ajustar√° el Modelo Lineal Generalizado y primero se evaluar√° si todas las variables fueron significativas.


```{r, echo=FALSE, message = FALSE, results = "hide"}

# Se divide la tabla
model_2_train <- glm(QUA_Desc_Num ~ Modelo + Moneda + Segmento_R + Elegible_UBER + Agencia_Taller + QC + Frenos +
                       Pasajeros_5 + Zona_volatilidad_Ord + SA_siniestro + Tipo_Zona_R + Carroceria_R + 
                       Municipio_Riesgo + Marca_TP_R + Estado,
                     data = benchmark_train,
                     family = "Gamma" (link = 'identity'))

summary(model_2_train)

```
De la estimaci√≥n lineal generalizada se obtuvo un Coeficiente de Informaci√≥n de Akaike (AIC) de $234,288$ y se observ√≥ que s√≥lo 1 variable no fu√© significativa:

|              Variable               |   p-valor     |
|:---------------------------:|:------:|
| **Frenos-"1"** | 20.5% |
Table: An√°lisis de Permanencia de Variables


La variable "Frenos" no es significativa cuando es la categor√≠a "1" (el veh√≠culo tiene frenos tipo ABS).

Se calcularon las m√©tricas comparativas para evaluar el tipo de ajuste.


```{r, echo=FALSE, message = FALSE, results = "hide"}
predict_model_2 <- predict(model_2_train, benchmark_validate[,c("Modelo", "Moneda", "Segmento_R", "Elegible_UBER","Agencia_Taller", 
                                                                "QC","Frenos", "Tipo_Zona_R", "Carroceria_R",
                                                                "Grado_Pobreza","Pasajeros_5", "Zona_volatilidad_Ord", "SA_siniestro",
                                                                "Siniestro_SA_2","Frenos", "Municipio_Riesgo", "Marca_TP_R", "Estado")])

dif_abs_model_2 <- mean(abs(predict_model_2 - benchmark_validate$QUA_Desc_Num))
dif_porc_model_2 <- mean(abs((predict_model_2 - benchmark_validate$QUA_Desc_Num)/benchmark_validate$QUA_Desc_Num))
eam_model_2 <- sqrt(mean((predict_model_2 - benchmark_validate$QUA_Desc_Num) ^ 2))

dif_abs_model_2
dif_porc_model_2
eam_model_2

```

| EPAM   | EAM    | ECM    |
|:------:|:------:|:------:|
| 12.8% | \$1,207 | \$1,852 |
Table: M√©tricas de Validaci√≥n del Modelo Lineal Generalizado


De los resultados obtenidos podemos concluir que el Modelo Lineal Generalizado se separa del precio real del seguro de autom√≥vil con cobertura amplia en alrededor del 12.8% que representa alrededor de $\$1,207$. Adem√°s, el $ECM$ indica que en promedio el modelo tiene una desviaci√≥n de $\$1,852$ de los datos reales.

\newpage

Finalmente procedemos a hacer un an√°lisis sobre los residuos estimados.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Correlaci√≥n Valores Reales y Estimados"}
plot(predict_model_2, benchmark_validate$QUA_Desc_Num, 
     xlab = "Valores Estimados (Base Validaci√≥n)", 
     ylab = "Valores Reales", xaxt = 'n', yaxt = 'n')
abline(0,1)
axis(1, at = pretty(predict_model_2), labels = paste0("$", pretty(predict_model_2)), las = 0.5)
axis(2, at = pretty(benchmark_validate$QUA_Desc_Num), labels = paste0("$", pretty(benchmark_validate$QUA_Desc_Num)), las = 0.5) 
```

Aunque s√≠ existe una relaci√≥n lineal entre los valores estimados y los reales pero se observa que los resultados para precios grandes sigue muy dispersa.

De manera similar al modelo lineal, se decidi√≥ transformar logaritmicamente la variable dependiente y la Suma Asegurada de la variable independiente para poder tener un modelo m√°s estable. Adicionalmente, se removi√≥ la variable "Frenos" para que todas las variables sean significativas. Adem√°s, se agreg√≥ el cuadrado del logaritmo.

Al estimar el modelo con transformaci√≥n logar√≠tmica (se us√≥ una funci√≥n enlace logar√≠tmica) se obtuvo un Coeficiente de Informaci√≥n de Akaike (AIC) de $234,358$ con todas las variables significativas y es inferior al modelo sin transformaci√≥n


```{r, echo=FALSE, message = FALSE, results = 'hide'}

model_2_train_log <- glm(QUA_Desc_Num ~ Modelo + Moneda + Segmento_R + Elegible_UBER + Agencia_Taller + QC + Frenos +
                           Pasajeros_5 + Zona_volatilidad_Ord + Log_Siniestro_SA + Log_Siniestro_SA_2 + Estado + 
                           Tipo_Zona_R + Carroceria_R + Municipio_Riesgo + Marca_TP_R,
                         data = benchmark_train,
                         family = "Gamma" (link = 'log'))

summary(model_2_train_log)

```

De la estimaci√≥n anterior se obtuvo un Coeficiente de Informaci√≥n de Akaike (AIC) de $232,750$ y se observ√≥ que s√≥lo 2 variable no fu√© significativa:

|              Variable               |   p-valor     |
|:---------------------------:|:------:|
| **Frenos-"Desconocido"** | 11.2% |
| **Carroceria_R-"OTROS"** | 60% |
Table: An√°lisis de Permanencia de Variables

Se calcularon las m√©tricas comparativas para evaluar el tipo de ajuste.


```{r, echo=FALSE, message = FALSE, results = "hide"}
predict_model_2_log <- predict(model_2_train_log, benchmark_validate[,c("Modelo", "Moneda", "Segmento_R", 
                                                                        "Elegible_UBER","Agencia_Taller", "Log_Siniestro_SA",
                                                                        "QC","Estado", "Frenos", "Tipo_Zona_R", "Carroceria_R",
                                                                        "Grado_Pobreza","Pasajeros_5", "Zona_volatilidad_Ord",
                                                                        "Log_Siniestro_SA_2","Frenos", "Municipio_Riesgo", "Marca_TP_R")])

dif_abs_model_2_log <- mean(abs(exp(predict_model_2_log) - benchmark_validate$QUA_Desc_Num))
dif_porc_model_2_log <- mean(abs((exp(predict_model_2_log) - benchmark_validate$QUA_Desc_Num)/benchmark_validate$QUA_Desc_Num))
eam_model_2_log <- sqrt(mean((exp(predict_model_2_log) - benchmark_validate$QUA_Desc_Num) ^ 2))

dif_abs_model_2_log
dif_porc_model_2_log
eam_model_2_log
```


| EPAM   | EAM    | ECM    |
|:------:|:------:|:------:|
| 12% | \$1,137 | \$1,757 |
Table: M√©tricas de Validaci√≥n el Modelo Lineal Generalizado con Transformaci√≥n Logar√≠tmica


De los resultados obtenidos podemos concluir que el Modelo Lineal Generalizado con transformaci√≥n logar√≠tmica se separa del precio real del seguro de autom√≥vil con cobertura amplia en alrededor del 12% que representa alrededor de $\$1,137$. Adem√°s, el $ECM$ indica que en promedio el modelo tiene una desviaci√≥n de $\$1,757$ de los datos reales. La transformaci√≥n logar√≠tmica no aumenta de manera significativa el poder predictivo del modelo.

Finalmente procedemos a hacer un an√°lisis sobre los residuos estimados del modelo con transformaci√≥n logar√≠tmica.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Correlaci√≥n Valores Reales y Estimados"}
plot(exp(predict_model_2_log), benchmark_validate$QUA_Desc_Num, 
     xlab = "Valores Estimados (Base Validaci√≥n)", 
     ylab = "Valores Reales",
     xaxt = 'n', yaxt = 'n') 
abline(0,1)
axis(1, at = pretty(exp(predict_model_2_log)), labels = paste0("$", pretty(exp(predict_model_2_log))), las = 0.5)
axis(2, at = pretty(benchmark_validate$QUA_Desc_Num), labels = paste0("$", pretty(benchmark_validate$QUA_Desc_Num)), las = 0.5) 

```
Existe una relaci√≥n lineal entre la estimaci√≥n con los valores reales y estimados, pero los valores estimados m√°s grandes siguen teniendo mayor variabilidad con el valor real, pero ya es menor la dispersi√≥n lo que indica que la transformaci√≥n logar√≠tmica fu√© adecuada para tener resultados m√°s estables.

Para ambos modelos se puede identificar que la distribuci√≥n gamma fu√© una buena estimaci√≥n ya que nos di√≥ resultados m√°s precisos que el modelo lineal. Adem√°s, la transformaci√≥n logar√≠tmica ofrece mejores resultados en t√©rminos de coeficientes de informaci√≥n. Ambas nos indican que es posible que los resultados sean precisos. Finalmente, al hacer una comparaci√≥n con las m√©tricas de validaci√≥n observamos lo siguiente:

| Modelo                     | EPAM    | EAM     | ECM     |
|:--------------------------:|:-------:|:-------:|:-------:|
| Sin Transformaci√≥n         | 12.8% |  \$1,207 | \$1,852 |
| Transformaci√≥n Logar√≠tmica | 12% | \$1,137  | \$1,757 |
Table: Comparativa de M√©tricas de Validaci√≥n

Aunque el modelo con transformaci√≥n logar√≠tmica ofrece resultados m√°s estables la predicci√≥n no mejora significativamente, pero al coeficiente de informaci√≥n es menor lo cual significa que tiene mejor ajuste. En conclusi√≥n el modelo con transformaci√≥n logar√≠tmica se usar√° para compararlo contra el resto de metodolog√≠as. 


### 5.6.3 Modelo XGradient Boosting

Para el modelo lineal se us√≥ la funci√≥n $xgboost$ con la paqueter√≠a de $xgboost$ de R. Para √©ste modelo el valor de los hiperpar√°metros es crucial. Aunque el modelo tiene muchos hiperpar√°metros (como los que se presentaron en el cap√≠tulo 3.2) se decidi√≥ enfocarse en los siguientes que se consideran los principales y hay m√°s gu√≠a sobre como encontrarlos:

+ $nrounds$, n√∫mero m√°ximo de iteraciones del algoritmo. Limitado a ser mayor o igual a $1$.
+ $eta$, la tasa de aprendizaje del modelo que est√° entre $0$ y $1$. La documentaci√≥n de la funci√≥n en $R$ indica que mientras el valor sea m√°s cercano a 0 se tiene un modelo con menos sobre ajuste. Adem√°s, entre m√°s bajo sea tambi√©n se debe aumentar el n√∫mero de iteraciones. Su valor por defecto es $0.3$.
+ $max\_depth$, es la profundidad de los √°rboles que generar√°. Su valor por defecto es $6$.

Para poder ajustar los hiperpar√°metros se decidi√≥ evaluar el modelo usando varios modelos con los cuales se puede identificar el mejor rendimiento.

El conjunto de hiperpar√°metros seleccionados fu√©:

+ $nrounds$ se har√°n iteraciones entre $400$, $500$ y $600$.

+ $eta$, se probaron iteraciones entre $0.05$ y $1$ con aumentos de $0.05$. Esto se hizo para evitar que el modelo tenga sobreajuste.

+ $max\_depth$, se dej√≥ fijo en $1$ y se ir√° aumentando hasta que el ajuste deje de mejorar.

Lo que se har√° es evaluar el modelo con cada par√°metro y seleccionar el mejor en funci√≥n del Error Cuadr√°tico Medio. Esto se hace con la funci√≥n de $trainControl$ del paquete $caret$ que hace Cross Validation con el Error Cuadr√°tico Medio para encontrar los par√°metros que minimicen esa funci√≥n objetivo. Una vez encontrados los par√°metros √≥ptimos se evaluar√° el modelo con las m√©tricas de validaci√≥n y se aumentar√° en $1$ el par√°metro de $max\_depth$ hasta que no haya mejora significativa en las m√©tricas. Finalmente, se usaron todas las variables de los cap√≠tulos anteriores y se transform√≥ la variable objetivo ya que se ha observado en los cap√≠tulos anteriores que tiene el mejor comportamiento.


```{r, echo=FALSE, message = FALSE, results = "hide"}
# Se divide la tabla
set.seed(123)
xg_benchmark_train <- benchmark_train[,c("Log_QUA_Desc_Num","Moneda", "Segmento_R", 
                                         "Elegible_UBER","Agencia_Taller",
                                         "QC","Estado", "Tipo_Zona_R",
                                         "Pasajeros_5", "Zona_volatilidad_Ord", "Log_Siniestro_SA", 
                                         "Log_Siniestro_SA_2", "Municipio_Riesgo", "Modelo","Marca_TP_R",  
                                         "Carroceria_R")]


xg_benchmark_validate <- benchmark_validate[,c("Log_QUA_Desc_Num","Moneda", "Segmento_R", 
                                               "Elegible_UBER","Agencia_Taller",
                                               "QC","Estado", "Tipo_Zona_R",
                                               "Pasajeros_5", "Zona_volatilidad_Ord", "Log_Siniestro_SA", "Log_Siniestro_SA_2",
                                               "Municipio_Riesgo", "Modelo","Marca_TP_R", "Carroceria_R")]


xg_benchmark_train <- fastDummies::dummy_cols(xg_benchmark_train, select_columns = c("Moneda", "Segmento_R", 
                                                                                     "Elegible_UBER","Agencia_Taller",
                                                                                     "QC","Estado", "Tipo_Zona_R",
                                                                                     "Pasajeros_5", "Zona_volatilidad_Ord",
                                                                                     "Municipio_Riesgo","Marca_TP_R", 
                                                                                     "Carroceria_R", "Modelo")
                                              , remove_first_dummy = TRUE)

xg_benchmark_train <- xg_benchmark_train[,-c("Moneda", "Segmento_R", 
                                             "Elegible_UBER","Agencia_Taller",
                                             "QC","Estado", "Tipo_Zona_R",
                                             "Pasajeros_5", "Zona_volatilidad_Ord",
                                             "Municipio_Riesgo","Marca_TP_R", "Carroceria_R", "Modelo")]


xg_benchmark_validate <- fastDummies::dummy_cols(xg_benchmark_validate, select_columns = c("Moneda", "Segmento_R", 
                                                                                           "Elegible_UBER","Agencia_Taller",
                                                                                           "QC","Estado", "Tipo_Zona_R",
                                                                                           "Pasajeros_5", "Zona_volatilidad_Ord",
                                                                                           "Municipio_Riesgo","Marca_TP_R", 
                                                                                           "Carroceria_R", "Modelo")
                                                 , remove_first_dummy = TRUE)

xg_benchmark_validate <- xg_benchmark_validate[,-c("Moneda", "Segmento_R", 
                                                   "Elegible_UBER","Agencia_Taller",
                                                   "QC","Estado", "Tipo_Zona_R",
                                                   "Pasajeros_5", "Zona_volatilidad_Ord",
                                                   "Municipio_Riesgo", "Marca_TP_R", "Carroceria_R", "Modelo")]



dtrain <- xgb.DMatrix(data = data.matrix(xg_benchmark_train[,-c("Log_QUA_Desc_Num")]),
                      label = data.matrix(xg_benchmark_train[, c("Log_QUA_Desc_Num")]))


dtest <-xgb.DMatrix(data = data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]),
                    label = data.matrix(xg_benchmark_validate[, c("Log_QUA_Desc_Num")]))



# -1 Iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 1, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 3, eta = 0.95, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 1, 
                  max_depth = 1)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_min_1 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_min_1 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_min_1 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_min_1
dif_porc_model_6_min_1
eam_model_6_min_1

# Zero Iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 2, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 3, eta = 0.95, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.95, 
                  max_depth = 2)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_0 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_0 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_0 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_0
dif_porc_model_6_0
eam_model_6_0

# Primera Iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 3, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 3, eta = 0.55, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.55, 
                  max_depth = 3)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_1 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_1 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_1 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_1
dif_porc_model_6_1
eam_model_6_1


# Segunda iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 4, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 4, eta = 0.45, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.45, 
                  max_depth = 4)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_2 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_2 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_2 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_2
dif_porc_model_6_2
eam_model_6_2


# Tercera iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 5, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 5, eta = 0.25, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.25, 
                  max_depth = 5)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_3 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_3 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_3 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_3
dif_porc_model_6_3
eam_model_6_3

# Cuarta iteraci√≥n
# Using Expand.grid
train_grid <- expand.grid(max_depth = 6, 
                          nrounds = c(400, 500, 600),
                          eta = seq(from = 0.05, to = 1, by = 0.05), 
                          gamma = 0,
                          subsample = 1,
                          min_child_weight = 1,
                          colsample_bytree = 0.6)

dtrain_y <- benchmark_train$Log_QUA_Desc_Num

train_control <- trainControl(method = "cv",
                              number = 5,
                              search = "grid")

#model_train <- train(xg_benchmark_train[, -c("Log_QUA_Desc_Num")], dtrain_y, method = "xgbTree", trControl = train_control, tuneGrid = train_grid, verbosity = 0)

# Tarda mucho pero el mejor modelo es
# RMSE was used to select the optimal model using the smallest value.
# The final values used for the model were nrounds = 600, max_depth = 6, eta = 0.25, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.


mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.15, 
                  max_depth = 6)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6_4 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6_4 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6_4 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6_4
dif_porc_model_6_4
eam_model_6_4

```

La siguiente tabla muestra las m√©tricas de validaci√≥n variando el par√°metro $max\_depth$:

| Par√°metro $max\_depth$ | EPAM |  EAM |   ECM  |
|:---------------------:|:----:|:----:|:------:|
|           1           | 9.23% | \$930 | $1,647 |
|           2           | 6.76% | \$677 | $1,304 |
|           3           | 6.26% | \$620 | $1,247 |
|           4           | 5.65% | \$556 | $1,174 |
|           5           | 5.69% | \$553 | $1,121 |
|           6           | 5.74% | \$558 | $1,149 |
Table: M√©tricas de Validaci√≥n por Profundidad del √Årbol


Se concluye que el mejor par√°metro para $max\_depth$ es $4$. Adem√°s, de acuerdo al resultado de la funci√≥n $trainControl$ los hiperpar√°metros que hacen el mejor ajuste de acuerdo al ECM son: 

+ $nrounds=400$ 

+ $eta=0.34$


```{r, echo=FALSE, message = FALSE, results = "hide"}
mode_6 <- xgboost(data = dtrain, 
                  verbose = 1, 
                  nrounds = 600, 
                  eta = 0.45, 
                  max_depth = 4)

predict_model_6 <- predict(mode_6, data.matrix(xg_benchmark_validate[, -c("Log_QUA_Desc_Num")]))


dif_abs_model_6 <- mean(abs(exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)))
dif_porc_model_6 <- mean(abs((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num))/exp(benchmark_validate$Log_QUA_Desc_Num)))
eam_model_6 <- sqrt(mean((exp(predict_model_6) - exp(benchmark_validate$Log_QUA_Desc_Num)) ^ 2))

dif_abs_model_6
dif_porc_model_6
eam_model_6
```

Como ya se hab√≠a mencionado, al estimar el modelo con los par√°metros anteriores y calcular las m√©tricas de error en la base de validaci√≥n se obtiene lo siguiente:

| EPAM   | EAM    | ECM    |
|:------:|:------:|:------:|
| 5.7% | \$556 | \$1,174 |
Table: M√©trica de Validaci√≥n


De los resultados obtenidos podemos concluir que la metodolog√≠a de XGradient Boosting se separa del precio real del seguro de autom√≥vil con cobertura amplia en alrededor del 5.7% que representa alrededor de $\$556$. Adem√°s, el $ECM$ indica que la desviaci√≥n promedio es $\$1,174$.

La paqueter√≠a de $xgboost$ de R contiene la funci√≥n $xgb.importance$ que calcula la importancia de las variables.

```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.height = 1.5, fig.width = 5, fig.cap = "Importancia de las Variables"}


importance_matrix <- xgb.importance(colnames(dtrain), model = mode_6)

importance <- importance_matrix[1:4]

importance$Nombre <- c("Logaritmo Suma asegurada", "Veh√≠culo de Taller", "Estado de M√©xico", "Segmento Cami√≥n")

#xgb.plot.importance(importance_matrix, 
#                    rel_to_first = FALSE, 
#                    xlab = "Importancia", 
#                    top_n = 4, 
#                    left_margin = 13) 

ggplot(importance, aes(x = reorder(Nombre , Gain), y = Gain)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  ggtitle("Importancia de Variables") +
  labs(x = "Variable", y = "Ganancia") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
  )


```

La variable que tiene m√°s importancia es la Suma Asegurada ("SA_siniestro" en su transformaci√≥n logar√≠tmica), lo cual tiene sentido ya que se observ√≥ que tienen una alta relaci√≥n. As√≠ mismo, el segmento "Cami√≥n" para el segmento del veh√≠culo ("Segmento_R_Camion") y los veh√≠culos que son de "Taller" tambi√©n son consideradas importantes al ser caracter√≠sticas del veh√≠culo. Finalmente, la caracter√≠stica geogr√°fica del asegurado en el Estado de M√©xico muestran valor predictivo.

Finalmente, procedemos a hacer un an√°lisis sobre los residuos del modelo de XGradient Boosting.


```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Correlaci√≥n Valores Reales y Estimados"}

plot(exp(predict_model_6), exp(benchmark_validate$Log_QUA_Desc_Num), 
     xlab = "Valores Estimados (Base Validaci√≥n)", 
     ylab = "Valores Reales", xaxt = 'n', yaxt = 'n')
abline(0,1)
axis(1, at = pretty(predict_model_6), labels = paste0("$", pretty(predict_model_6)), las = 0.5)
axis(2, at = pretty(benchmark_validate$Log_QUA_Desc_Num), labels = paste0("$", pretty(benchmark_validate$Log_QUA_Desc_Num)), las = 0.5) 
```
\newpage

Se observa que existe una relaci√≥n lineal poco dispersa entre los Valores Estimados con los Valores Reales. Las dispersiones moderadas reflejan que hay algunos errores, pero no parecen sistem√°ticos o extremadamente graves.


## 5.7 Validaci√≥n de los Modelos


Como se coment√≥ en cap√≠tulos anteriores se har√° una comparaci√≥n de las m√©tricas entre los modelos para poder obtener aquel que tenga mejor predicci√≥n. La siguiente tabla muestra las m√©tricas de los modelos en el 20% de datos reservado para la validaci√≥n.

|           Modelo           |  EPAM  |   EAM  |   ECM  |
|:--------------------------:|:------:|:------:|:------:|
|      Regresi√≥n Lineal      | 11.80% | \$1,136 | \$1,764 |
| Modelo Lineal Generalizado | 12% | \$1,137 | \$1,757 |
|     XGradient Boosting     |  5.7% |  \$556 | \$1,174 |
Table: Comparativa Entre Modelos

De los resultados, se observa que el modelo con el poder predictivo m√°s alto es la t√©cnica de Machine Learning de XGradient Boosting.

Adicionalmente, siguiendo la propuesta de validaci√≥n del Cap√≠tulo 4 se hace la comapraci√≥n visual para cada una de las variables m√°s importantes.


```{r, echo=FALSE, message = FALSE, results = "hide", fig.align = "center", fig.cap = "Validaci√≥n con la Variable de Suma Asegurada", fig.height = 4, fig.width = 6}
# Por Variable
benchmark_validate[,':='(model_1 = predict_model_1,
                         model_1_log = predict_model_1_log,
                         model_2 = predict_model_2,
                         model_2_log = predict_model_2_log,
                         model_6 = predict_model_6)]

benchmark_validate[,':='(SA_Intervalo_5 = cut(SA_siniestro, breaks = 5),
                         SA_Intervalo_10 = cut(SA_siniestro, breaks = 10),
                         SA_Intervalo_20 = cut(SA_siniestro, breaks = 20),
                         SA_Intervalo_30 = cut(SA_siniestro, breaks = 30, dig.lab = 10),
                         SA_Intervalo_200 = cut(SA_siniestro, breaks = 200))]

df <- benchmark_validate[, .(cotizacion_prom = mean(QUA_Desc_Num),
                             cotizacion_prom_model_1 = mean(model_1),
                             cotizacion_prom_model_1_log = mean(exp(model_1_log)),
                             cotizacion_prom_model_2 = mean(model_2),
                             cotizacion_prom_model_2_log = mean(exp(model_2_log)),
                             cotizacion_prom_model_6 = mean(exp(model_6)),
                             total_datos = .N),by = .(SA_Intervalo_30)]

label <- as.factor(c("$314-$363",	"$218-$266",	"$266-$314", "$121-$169",	"$508-$557",	
                            "$169-$218",	"$72-$121",	"$22-$72",	"$363-$411",	"$460-$508",	
                            "$411-$460",	"$557-$605",	"$750-$799",	"$654-$702",	"$1,138-$1,187",	
                            "$605-$654",	"$896-$944",	"$702-$750",	"$847-$896",	"$1,090-$1,138",	
                            "$1,187-$1,235",	"$992-$1,041",	"$944-$993",	"$799-$847",	"$1,235-$1,283",	
                            "$1,429-$1,478",	"$1,283-$1,331"))


fig <- ggplot(df) + 
  geom_col(aes(x = as.factor(SA_Intervalo_30), y = total_datos * 1)) + 
  geom_line(aes(x = as.factor(SA_Intervalo_30), y = cotizacion_prom / 100, colour="Precio Real"), group = 2) +
  geom_line(aes(x = as.factor(SA_Intervalo_30), y = cotizacion_prom_model_1_log / 100, colour="Modelo Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(SA_Intervalo_30), y = cotizacion_prom_model_2_log / 100, colour="MLG Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(SA_Intervalo_30), y = cotizacion_prom_model_6 / 100, colour="XGBoost"), group = 2) +
  scale_color_manual(name = "", values = c("Precio Real" = "black",
                                           "Modelo Log-Lineal" = "blue",
                                           "MLG Log-Lineal" = "red",
                                           "XGBoost" = "green")) +
  theme_classic() + 
  scale_x_discrete(guide = guide_axis(angle = 90), labels = label) +
  xlab("Segmentos de Suma Asegurada (en miles)") +
  ylab("N√∫mero de Cotizaciones")
fig

```

Para la Suma Asegurada con 30 intervalos se obseva como todos los modelos tienen un ajuste adecuado para los primeros intervalos. Sin embargo, para los valores m√°s altos como el intervalo \$1,187-\$1,235 de Suma Asegurada donde no hay muchos datos se observa que la predicci√≥n usando la t√©cnica de Machine Learning es m√°s precisa que las metodolog√≠as tradicionales. Sin embargo, en la pen√∫ltima categor√≠a de Suma Aseguradas m√°s altas donde el Modelo Lineal fu√© m√°s preciso de manera m√°s significativa pero s√≥lo se debe al bajo n√∫mero de cotizaciones. Observando la Suma aSegurada se observa que en general todos los modelos tuvieron un valor predictivo similar.


```{r, echo=FALSE, message = FALSE, fig.cap = "Variable Municipio (mayor a 50 cotizaciones)", fig.height = 4, fig.width = 6}

df <- benchmark_validate[, .(cotizacion_prom = mean(QUA_Desc_Num),
                             cotizacion_prom_model_1 = mean(model_1),
                             cotizacion_prom_model_1_log = mean(exp(model_1_log)),
                             cotizacion_prom_model_2 = mean(model_2),
                             cotizacion_prom_model_2_log = mean(exp(model_2_log)),
                             cotizacion_prom_model_6 = mean(exp(model_6)),
                             total_datos = .N),by = .(Municipio_D)][total_datos >= 50]
fig <- ggplot(df) + 
  geom_col(aes(x = as.factor(Municipio_D), y = total_datos * 1)) + 
  geom_line(aes(x = as.factor(Municipio_D), y = cotizacion_prom / 100, colour="Precio Real"), group = 2) +
  geom_line(aes(x = as.factor(Municipio_D), y = cotizacion_prom_model_1_log / 100, colour="Modelo Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(Municipio_D), y = cotizacion_prom_model_2_log / 100, colour="MLG Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(Municipio_D), y = cotizacion_prom_model_6 / 100, colour="XGBoost"), group = 2) +
  scale_color_manual(name = "", values = c("Precio Real" = "black",
                                           "Modelo Log-Lineal" = "blue",
                                           "MLG Log-Lineal" = "red",
                                           "XGBoost" = "green")) +
  theme_classic() + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  xlab("Municipio") +
  ylab("N√∫mero de Cotizaciones")

fig
```


Para esta variable, se realiz√≥ un an√°lisis gr√°fico considerando √∫nicamente los municipios con m√°s de 50 cotizaciones, lo que permite una mejor visualizaci√≥n de los resultados. No obstante, m√°s adelante se presenta un an√°lisis de m√©tricas que incluye al resto de los municipios.

Se observa que el modelo de XGBoost presenta predicciones muy cercanas al Precio Real del Seguro en la mayor√≠a de los municipios. Adem√°s, este modelo muestra un mejor ajuste en los llamados "Municipios Especiales", caracterizados por una alta variabilidad. Por ejemplo, en Atizap√°n de Zaragoza, la predicci√≥n de XGBoost supera significativamente a la de los dem√°s modelos, gracias a su capacidad para capturar los efectos asociados a dicha categor√≠a. En el municipio de Tehuac√°n, XGBoost tambi√©n logra un mejor ajuste, aunque en otros casos (como San Pedro Tlaquepaque) ninguno de los modelos evaluados ofrece un desempe√±o satisfactorio. A diferencia del an√°lisis de la Suma Asegurada, donde no se identific√≥ un modelo claramente superior, en este caso se observa que, en t√©rminos generales, XGBoost ofrece la predicci√≥n m√°s precisa. Adem√°s, la t√©cnica de XGradient Boosting tiene una mejor estimaci√≥n para la mayor parte de las categor√≠as en Municipio podemos determinar que es el mejor modelo ya que ofrece una predicci√≥n m√°s precisa a nivel Zona de cotizaci√≥n. 

\newpage

Para aquellos municipios donde hubo menos de 50 cotizaciones (m√°s de 200 Municipios) es dif√≠cil crear una comparaci√≥n visual similar a las anteriores. Por lo que se decidi√≥ hacer una comparaci√≥n de m√©tricas de error para poder evaluar la variable en todas sus categor√≠as.


```{r, echo=FALSE, message = FALSE, results = "hide"}

df <- benchmark_validate[, .(cotizacion_prom = mean(QUA_Desc_Num),
                             cotizacion_prom_model_1 = mean(model_1),
                             cotizacion_prom_model_1_log = mean(exp(model_1_log)),
                             cotizacion_prom_model_2 = mean(model_2),
                             cotizacion_prom_model_2_log = mean(exp(model_2_log)),
                             cotizacion_prom_model_6 = mean(exp(model_6)),
                             total_datos = .N),by = .(Municipio_D)][total_datos < 50]

epam_ml <- mean(abs((df$cotizacion_prom_model_1_log - df$cotizacion_prom)/df$cotizacion_prom))
eam_ml <- mean(abs(df$cotizacion_prom - df$cotizacion_prom_model_1_log))
ecm_ml <- sqrt(mean((df$cotizacion_prom_model_1_log - df$cotizacion_prom) ^ 2))

epam_mlg <- mean(abs((df$cotizacion_prom_model_2_log - df$cotizacion_prom)/df$cotizacion_prom))
eam_mlg <- mean(abs(df$cotizacion_prom - df$cotizacion_prom_model_2_log))
ecm_mlg <- sqrt(mean((df$cotizacion_prom_model_2_log - df$cotizacion_prom) ^ 2))

epam_xgb <- mean(abs((df$cotizacion_prom_model_6 - df$cotizacion_prom)/df$cotizacion_prom))
eam_xgb <- mean(abs(df$cotizacion_prom - df$cotizacion_prom_model_6))
ecm_xgb <- sqrt(mean((df$cotizacion_prom_model_6 - df$cotizacion_prom) ^ 2))

epam_ml
eam_ml
ecm_ml

epam_mlg
eam_mlg
ecm_mlg

epam_xgb
eam_xgb
ecm_xgb

ref <- unique(df$Municipio_D)
#nrow(ref)
nrow(benchmark_validate)
nrow(benchmark_validate[Municipio_D %in% ref])

```


|           Modelo           |  EPAM  |   EAM  |   ECM  |
|:--------------------------:|:------:|:------:|:------:|
|      Regresi√≥n Lineal      | 14.25% | \$1,288 | \$1,909 |
| Modelo Lineal Generalizado | 14.76% | \$1,296 | \$1,892 |
|     XGradient Boosting     | 9.4% | \$827 | \$1,352 |
Table: Comparativa Entre Modelos por Municipio


De acuerdo a las m√©tricas de arriba el modelo con mejor estimaci√≥n es el modelo de XGradient Boosting al reducir todas las m√©tricas de error. Por lo tanto se tiene una mejor predicci√≥n por parte del modelo de XGradient Boosting.

De la validaci√≥n gr√°fica se concluye que a un nivel Municipio el modelo XGradient Boosting representa una mejora significativa respecto a las otras metodolog√≠as tradicionales; adem√°s, la variable Municipio es una variable que identifica la zona por lo que la mejora observada es importante.  

La siguiente gr√°fica es la variable sobre la amrca del autom√≥vil.

```{r, echo=FALSE, message = FALSE, fig.cap = "Variable Marca", fig.height = 4, fig.width = 6}
df <- benchmark_validate[, .(cotizacion_prom = mean(QUA_Desc_Num),
                             cotizacion_prom_model_1 = mean(model_1),
                             cotizacion_prom_model_1_log = mean(exp(model_1_log)),
                             cotizacion_prom_model_2 = mean(model_2),
                             cotizacion_prom_model_2_log = mean(exp(model_2_log)),
                             cotizacion_prom_model_6 = mean(exp(model_6)),
                             total_datos = .N),by = .(Marca_TP)]
fig <- ggplot(df) + 
  geom_col(aes(x = as.factor(Marca_TP), y = total_datos * 1)) + 
  geom_line(aes(x = as.factor(Marca_TP), y = cotizacion_prom / 80, colour="Precio Real"), group = 2) +
  geom_line(aes(x = as.factor(Marca_TP), y = cotizacion_prom_model_1_log / 80, colour="Modelo Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(Marca_TP), y = cotizacion_prom_model_2_log / 80, colour="MLG Log-Lineal"), group = 2) +
  geom_line(aes(x = as.factor(Marca_TP), y = cotizacion_prom_model_6 / 80, colour="XGBoost"), group = 2) +
  scale_color_manual(name = "", values = c("Precio Real" = "black",
                                           "Modelo Log-Lineal" = "blue",
                                           "MLG Log-Lineal" = "red",
                                           "XGBoost" = "green")) +
  theme_classic() + 
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  xlab("Marca") +
  ylab("N√∫mero de Cotizaciones")

fig
```

\newpage

Cuando se hace la comparaci√≥n por Marca se observa que en general todos los modelos siguen el comportamiento del Precio del Seguro. Sin embargo, existen algunas categor√≠as donde el comportamiento de XGradient Boosting es m√°s parecido al Precio Real que el resto de modelos, por ejemplo para la marca ACURA, Porsche, Seat y HINO MOTORS se observa una mejora significativa respecto al resto de modelos. Sin embargo, para la categor√≠a de LAND ROVER el modelo con mayor error es XGradient Boosting, pero su error no es muy diferente comparado al resto de modelos. De la gr√°fica se concluye que el modelo con mejor predicci√≥n es XGradient Boosting. Sin embargo, para esta variable todos los modelos tienen una predicci√≥n cercana al valor real.

Aunque esta comparaci√≥n visual no es definitiva, se observa que el modelo de XGradient Boosting ofrece mejores resultados a un nivel desagregado. 

Como se estableci√≥ en el cap√≠tulo 4, se hizo otra validaci√≥n vidual usando la gr√°ficas de cuantiles se hicieron con los datos de validaci√≥n.


```{r, echo=FALSE, message = FALSE, fig.align = "center", fig.cap = "Gr√°ficos de Cuantiles", fig.height = 6, fig.width = 8}

#plot_grid(graph_1, graph_2)

dt <- benchmark_validate[,c("QUA_Desc_Num","model_1_log", "model_2_log","model_6")]

# Modelo Lineal
# Crear deciles (10 cuantiles) basados en la prima estimada
dt[, quantile := cut(exp(dt$model_1_log),
                     breaks = quantile(exp(dt$model_1_log), probs = seq(0, 1, 0.1)),
                     include.lowest = TRUE, labels = FALSE)]

# Calcular promedio por cuantil
summary_dt <- dt[, .(
  promedio_real = mean(QUA_Desc_Num),
  promedio_estimado = mean(exp(model_1_log))
), by = quantile]

lift_value_1 <- summary_dt[quantile == 10, promedio_real] - summary_dt[quantile == 1, promedio_real]

# Formato largo para ggplot
plot_dt <- melt(summary_dt, id.vars = "quantile",
                variable.name = "tipo", value.name = "Precio_Real")

# Graficar
graph_1 <- ggplot(plot_dt, aes(x = quantile, 
                               y = Precio_Real, 
                               color = tipo)) +
           geom_line(linewidth = 0.2) +
           geom_point(size = 0.4) +
           labs(x = "Decil",
                y = "Precios Promedio (en miles)",
                color = "Tipo de Precio"
                ) +
  scale_x_continuous(breaks = 1:10) +
  labs(title = c(paste("Modelo Lineal\nLift ", round(lift_value_1, 0)))) +
  scale_y_continuous(labels = scales::dollar_format(scale = 0.001)) +
  scale_color_manual(values = c("promedio_real" = "red", "promedio_estimado" = "blue")) +
  theme(legend.position = "none", 
        plot.subtitle = element_text(size = 6),
        axis.title.y = element_text(size = 8),
        axis.title.x = element_text(size = 8),
        plot.title = element_text(size = 8, 
                                  face = "bold", 
                                  hjust = 0  # 0 = izquierda, 0.5 = centro, 1 = derecha
    ))



# Modelo GLM
dt <- benchmark_validate[,c("QUA_Desc_Num","model_1_log", "model_2_log","model_6")]

# Crear deciles (10 cuantiles) basados en la prima estimada
dt[, quantile := cut(exp(dt$model_2_log),
                     breaks = quantile(exp(dt$model_2_log), probs = seq(0, 1, 0.1)),
                     include.lowest = TRUE, labels = FALSE)]

# Calcular promedio por cuantil
summary_dt <- dt[, .(
  promedio_real = mean(QUA_Desc_Num),
  promedio_estimado = mean(exp(model_2_log))
), by = quantile]

lift_value_2 <- summary_dt[quantile == 10, promedio_real] - summary_dt[quantile == 1, promedio_real]

# Formato largo para ggplot
plot_dt <- melt(summary_dt, id.vars = "quantile",
                variable.name = "tipo", value.name = "Precio_Real")

# Graficar
graph_2 <- ggplot(plot_dt, aes(x = quantile, y = Precio_Real, color = tipo)) +
  geom_line(linewidth = 0.2) +
  geom_point(size = 0.4) +
  labs(
       x = "Decil",
       y = "Precios Promedio (en miles)",
       color = "Tipo de Precio") +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(labels = scales::dollar_format(scale = 0.001)) +
  scale_color_manual(values = c("promedio_real" = "red", "promedio_estimado" = "blue"),
                     labels = c("Precio Real", "Precio Estimado")) +
  labs(title = c(paste("Modelo Lineal Generalizado\nLift ", round(lift_value_2, 0)))) +
  theme(legend.position = "none", 
        axis.title.y = element_text(size = 8), 
        plot.subtitle = element_text(size = 6),
        axis.title.x = element_text(size = 8),
        plot.title = element_text(size = 8, 
                                  face = "bold", 
                                  hjust = 0  # 0 = izquierda, 0.5 = centro, 1 = derecha
    ))



# Modelo XGradient Boosting
dt <- benchmark_validate[,c("QUA_Desc_Num","model_1_log", "model_2_log","model_6")]

# Crear deciles (10 cuantiles) basados en la prima estimada
dt[, quantile := cut(exp(dt$model_6),
                     breaks = quantile(exp(dt$model_6), probs = seq(0, 1, 0.1)),
                     include.lowest = TRUE, labels = FALSE)]

# Calcular promedio por cuantil
summary_dt <- dt[, .(
  promedio_real = mean(QUA_Desc_Num),
  promedio_estimado = mean(exp(model_6))
), by = quantile]

lift_value_3 <- summary_dt[quantile == 10, promedio_real] - summary_dt[quantile == 1, promedio_real]

# Formato largo para ggplot
plot_dt <- melt(summary_dt, id.vars = "quantile",
                variable.name = "tipo", value.name = "Precio_Real")




# Graficar

graph_3 <- ggplot(plot_dt, aes(x = quantile, y = Precio_Real, color = tipo)) +
  geom_line(linewidth = 0.2) +
  geom_point(size = 0.4) +
  labs(
       x = "Decil",
       y = "Precios Promedio (en miles)",
       color = "Tipo de Precio") +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(labels = scales::dollar_format(scale = 0.001)) +
  scale_color_manual(values = c("promedio_real" = "red", "promedio_estimado" = "blue"),
                     labels = c("Precio Real", "Precio Estimado")) +
  labs(title = c(paste("XGradient Boosting\nLift ", round(lift_value_3, 0)))) +
  theme(axis.title.y = element_text(size = 9),
        legend.text = element_text(size = 9),
        legend.title = element_text(size = 9),
        legend.key.size = unit(0.25, "cm"), 
        plot.subtitle = element_text(size = 6),
        axis.title.x = element_text(size = 8),
        plot.title = element_text(size = 8, 
                                  face = "bold", 
                                  hjust = 0  # 0 = izquierda, 0.5 = centro, 1 = derecha
    ))


#plot_grid(title, graph_1, graph_2, graph_3)
fila_superior <- plot_grid(graph_1, 
                           graph_2, 
                           ncol = 2)



# Fila inferior: gr√°fica centrada (entre dos espacios vac√≠os)
fila_inferior <- plot_grid(
  graph_3, plot_spacer() + theme_nothing(),
  ncol = 2,
  #ncol = 3,
  rel_widths = c(2, 1) 
  #rel_widths = c(1, 2, 1)  # C entra al centro, m√°s grande, centrada perfectamente
)


# Juntar ambas filas
plot_grid(
  fila_superior,
  fila_inferior,
  ncol = 1,
  rel_heights = c(1, 1)
)


```

De las gr√°ficas de cuantiles anteriores se observa que todos los modelos est√°n cerca al valor real y crecen de la misma forma. Sin embargo, el primer y √∫ltimo decil del Modelo Lineal se separan del valor real, y el sexto decil del gr√°fico de cuantiles del Modelo Lineal Generalizado existe una separaci√≥n significativa. Pero, para el modelo de XGradient Boosting no se observa una separaci√≥n por lo que el este modelo parece predecir de forma m√°s precisa los valores reales. Finalmente, el ‚Äúlift‚Äù del modelo de XGradient Boosting es mayor que el resto de los modelos, es decir la metodolog√≠a de Machine Learning identifica mejor los valores m√°s grandes y m√≠nimos del precio real, por lo que el modelo con mejores caracter√≠sticas predictivas es el modelo de XGradient Boosting.

A partir de los resultados de las m√©tricas de validaci√≥n, la comparaci√≥n visual por categor√≠a y los gr√°ficos de cuantiles, se concluye que el modelo con mejor desempe√±o predictivo es XGBoost. Este resultado se atribuye principalmente a la alta n√∫mero de variables explicativas categ√≥ricas en los datos.

\newpage

# 6. Conclusi√≥n

Las metodolog√≠as estad√≠sticas como la Regresi√≥n Lineal y la Regresi√≥n Lineal Generalizada han sido ampliamente utilizadas en el sector asegurador debido a su interpretabilidad, facilidad de implementaci√≥n y una amplia base bibliogr√°fica. Sin embargo, en la √∫ltima d√©cada, los modelos de Machine Learning han ganado relevancia en la industria de los seguros, integr√°ndose cada vez m√°s en las herramientas empleadas por los Actuarios. Aunque estas metodolog√≠as ya eran conocidas, su adopci√≥n y expansi√≥n han sido posibles gracias al aumento del poder computacional en los √∫ltimos a√±os. Adem√°s, los modelos de Machine Learning han demostrado mejoras significativas en t√©rminos de capacidad predictiva, superando en muchos casos a los m√©todos tradicionales. Adem√°s, presentan la ventaja de no requerir supuestos estrictos sobre la distribuci√≥n de los datos. No obstante, estos beneficios no siempre son aplicables en todos los contextos: en ciertas situaciones, la interpretabilidad de los par√°metros sigue siendo un aspecto prioritario. Por ejemplo, algunos reguladores o empresas optan por seguir utilizando metodolog√≠as tradicionales, al no estar dispuestos a asumir el riesgo operativo o de modelo asociado a enfoques m√°s recientes. Si bien existen herramientas como los Partial Dependence Plots (PDP) que permiten interpretar modelos como XGBoost, estas interpretaciones no suelen ser tan directas ni tan claras como las que ofrecen los m√©todos estad√≠sticos cl√°sicos.

El modelo de XGradient Boosting al ser una optimizaci√≥n de los modelos de Gradient Boosting Machine demuestra en este trabajo ser un ejemplo donde el modelo de Machine Learning es una mejora significativa respecto al resto de modelos ya que no es importante entender los par√°metros del modelo (s√≥lo nos interesa poder predecir el precio), el error se reduce de manera significativa, y el tiempo para encontrar los par√°metros no es grande. Aunque se pudieron usar otras metodolog√≠as que pudieron aprovechar las caracter√≠sticas geogr√°ficas del asegurado (como Modelos Lineales Mixtos) √©sta metodolog√≠a demostr√≥ obtener buenos resultados. Adicionalmente, algunas variables econ√≥micas o sociales como el Grado de Pobreza o Grado de Delincuencia se pudieron agregar para poder tener una mejor representaci√≥n del riesgo de la ubicaci√≥n. Sin embargo, a pesar de las limitaciones mencionadas en las variables el modelo de XGradient Boosting fu√© la mejor alternativa; por lo tanto, se puede concluir que existen problemas en la industria de los seguros donde sin hacer an√°lisis complejos en las variables que puedan derivar en aumento de supuestos, o sin considerar factores ex√≥genos al asegurado podemos obtener un alto nivel de precisi√≥n en la predicci√≥n gracias a las t√©cnicas de Machine Learning.

Finalmente, el trabajo tambi√©n demuestra que el modelo de XGradient Boosting puede mejorar la predicci√≥n en los precios de seguros de autom√≥vil con cobertura amplia de la competencia cuando solamente se tengan √©stos datos y sin mayor informaci√≥n por parte de la competencia sobre su estimaci√≥n. Con estas predicciones se puede agregar al c√°lculo del precio justo para incluir el comportamiento del mercado. Las metodolog√≠as de Machine Learning son una oportunidad para obtener mejores resultados en el √°rea de Seguros si los ocupamos en problemas donde la predictibilidad es m√°s importante que la interpretaci√≥n, y donde no sea costosa la implementaci√≥n. 

\newpage

# Bibliograf√≠a

+ Piet de Jong y Gillian Z. (2008). Generalized Linear Models for Insurance Data. (2¬∞ ed.). Cambridge University Press.

+ Tianqi Chen y Carlos Guestrin (2016).XGBoost: A Scalable Tree Boosting System. University of Washington.

+ Gareth James, Daniela Witten, Trevor Hastie y Robert Tibshirani. (2013). An Introduction to Statistical Learning with Applications in R (2¬∞ ed.). Springer.

+ Asociaci√≥n Mexicana de Instituciones de Seguros. (2021). Sistema Estad√≠stico del Sector Asegurador del ramo Autom√≥viles.

+ Ley de Caminos, Puentes y Autotransporte Federal. (2023). C√°mara de Diputados del H. Congreso de la Uni√≥n.

+ Gobierno de M√©xico. (2021). La CONDUSEF te da las cuentas claras del sector asegurador, para el seguro de auto al segundo trimestre de 2021. Condusef. https://www.condusef.gob.mx/?p=contenido&idc=1791&idcat=1 

+ Mark Goldburd, Anand Khare, Dan Tevet, Dmitriy Guller. (2020). Generalized Linear Models for Insurance Rating (2¬∞ ed.).

+ Amazon Web Services Inc. (2024). How XGBoost works - amazon sagemaker. https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-HowItWorks.html 

+ Neter, J., Wasserman, W., & Kutner, M. H. (1983). Applied Linear Regression Models. R.D. Irwin. 

+ Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, Chen K, Mitchell R, Cano I, Zhou T, Li M, Xie J, Lin M, Geng Y, Li Y, Yuan J (2024). _xgboost: Extreme Gradient Boosting_. R package version 1.7.7.1,
  <https://CRAN.R-project.org/package=xgboost>.

+ Venables, W. N. & Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth Edition. Springer, New York. ISBN 0-387-95457-0

+ H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.

+ Barrett T, Dowle M, Srinivasan A, Gorecki J, Chirico M, Hocking T (2024). _data.table: Extension of `data.frame`_. R package version 1.15.4, <https://CRAN.R-project.org/package=data.table>.

+ Therneau T, Atkinson B (2023). _rpart: Recursive Partitioning and Regression Trees_. R package version 4.1.23, <https://CRAN.R-project.org/package=rpart>.

+ Kaplan J (2023). _fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from Categorical Variables_. R
  package version 1.7.3, <https://CRAN.R-project.org/package=fastDummies>.
  
+ Wilke C (2024). _cowplot: Streamlined Plot Theme and Plot Annotations for 'ggplot2'_. R package version 1.1.3, <https://CRAN.R-project.org/package=cowplot>.

+ R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.

